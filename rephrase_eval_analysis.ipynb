{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV Rephrased Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path):\n",
    "    # Initialize an empty list to store the data\n",
    "    data_list = []\n",
    "\n",
    "    # Open the CSV file for reading\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        # Create a CSV reader object\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            # Append the row (as a dictionary) to the data_list\n",
    "            row[\"choices\"] = ast.literal_eval(row[\"choices\"])\n",
    "\n",
    "            rephrase_params = [\"concept\", \"name\", \"option\"]\n",
    "            for param in rephrase_params:\n",
    "                if row[param] == \"True\":\n",
    "                    row[param] = True\n",
    "                elif row[param] == \"False\":\n",
    "                    row[param] = False\n",
    "                else:\n",
    "                    raise TypeError(f\"{param} data cannot be recognized\")\n",
    "\n",
    "            data_list.append(row)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def load_all_rephrase_data(split, dir_path, file_name):\n",
    "    data = {}\n",
    "    \n",
    "    for s in split:\n",
    "        file_path = f\"{dir_path}/{s}{file_name}\"\n",
    "        data[s] = load_csv_data(file_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "split = [\"validation\", \"test\", \"train\"]\n",
    "\n",
    "v1_data = load_all_rephrase_data(split, \"91123\", \"_rephrased_clean_name_2_91123.csv\")\n",
    "v2_data = load_all_rephrase_data(split, \"91223\", \"_rephrased_name_91223.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Rephrased Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(samples, file_path):\n",
    "    # Get the keys from the first dictionary\n",
    "    header = samples[0].keys()\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the data\n",
    "        for row in samples:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f'CSV file \"{file_path}\" has been created with the data.')\n",
    "\n",
    "def sample_data(split_type, v1_data, v2_data, idxs, file_name, fraction=0.5):\n",
    "    num_sampled = int(len(idxs) * fraction)\n",
    "    idx_test_sampled = random.sample(idxs, num_sampled)\n",
    "    v1_test_sampled = [v1_data[split_type][i] for i in idx_test_sampled]\n",
    "    v2_test_sampled = [v2_data[split_type][i] for i in idx_test_sampled]\n",
    "\n",
    "    save_data(v1_test_sampled, f\"./eval/v1_{split_type}_{file_name}\")\n",
    "    save_data(v2_test_sampled, f\"./eval/v2_{split_type}_{file_name}\")\n",
    "\n",
    "def sample_test_val_data(split_type, v1_data, v2_data):\n",
    "    v1_test_name = [idx for idx, data in enumerate(v1_data[split_type]) if data[\"name\"] and (not data[\"concept\"] and not data[\"option\"])]\n",
    "    v2_test_name = [idx for idx, data in enumerate(v2_data[split_type]) if data[\"name\"] and (not data[\"concept\"] and not data[\"option\"])]\n",
    "\n",
    "    assert v1_test_name == v2_test_name\n",
    "\n",
    "    v1_test_concept = [idx for idx, data in enumerate(v1_data[split_type]) if data[\"concept\"] and not data[\"option\"]]\n",
    "    v2_test_concept = [idx for idx, data in enumerate(v2_data[split_type]) if data[\"concept\"] and not data[\"option\"]]\n",
    "\n",
    "    assert v1_test_concept == v2_test_concept\n",
    "\n",
    "    v1_test_option = [idx for idx, data in enumerate(v1_data[split_type]) if data[\"option\"] and not data[\"concept\"]]\n",
    "    v2_test_option = [idx for idx, data in enumerate(v2_data[split_type]) if data[\"option\"] and not data[\"concept\"]]\n",
    "\n",
    "    assert v1_test_option == v2_test_option\n",
    "\n",
    "    v1_test_both = [idx for idx, data in enumerate(v1_data[split_type]) if data[\"option\"] and data[\"concept\"]]\n",
    "    v2_test_both = [idx for idx, data in enumerate(v2_data[split_type]) if data[\"option\"] and data[\"concept\"]]\n",
    "\n",
    "    assert v1_test_both == v2_test_both\n",
    "    \n",
    "    print(f\"Statistics for split: {split_type}\")\n",
    "    print(f\"Name only cases: {len(v1_test_name)}\")\n",
    "    print(f\"Concept only cases: {len(v1_test_concept)}\")\n",
    "    print(f\"Option only cases: {len(v1_test_option)}\")\n",
    "    print(f\"Both concept and option cases: {len(v1_test_both)}\")\n",
    "\n",
    "    permutations_idxs = {\n",
    "        \"name\": v1_test_name,\n",
    "        \"concept\": v1_test_concept,\n",
    "        \"option\": v1_test_option,\n",
    "        \"both\": v1_test_both\n",
    "    }\n",
    "\n",
    "    for s_type, idxs in permutations_idxs.items():\n",
    "        if split_type == \"train\":\n",
    "            sample_data(split_type, v1_data, v2_data, idxs, f\"{s_type}.csv\", fraction=0.1)\n",
    "        else:\n",
    "            sample_data(split_type, v1_data, v2_data, idxs, f\"{s_type}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for split: train\n",
      "Name only cases: 901\n",
      "Concept only cases: 277\n",
      "Option only cases: 816\n",
      "Both concept and option cases: 168\n",
      "CSV file \"./eval/v1_train_name.csv\" has been created with the data.\n",
      "CSV file \"./eval/v2_train_name.csv\" has been created with the data.\n",
      "CSV file \"./eval/v1_train_concept.csv\" has been created with the data.\n",
      "CSV file \"./eval/v2_train_concept.csv\" has been created with the data.\n",
      "CSV file \"./eval/v1_train_option.csv\" has been created with the data.\n",
      "CSV file \"./eval/v2_train_option.csv\" has been created with the data.\n",
      "CSV file \"./eval/v1_train_both.csv\" has been created with the data.\n",
      "CSV file \"./eval/v2_train_both.csv\" has been created with the data.\n"
     ]
    }
   ],
   "source": [
    "sample_test_val_data(\"train\", v1_data, v2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
