{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pygsheets\n",
    "import pandas as pd\n",
    "import openai\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pygsheets.authorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers_ids = ['W1', 'W2', 'W3', 'W4', 'W5', 'W6']\n",
    "id_to_key_task1 = {\n",
    "    'ind': {\n",
    "        'W1': '14dAiIsBLxBUHzXgFDznMjSXCJmFY6qnIWOADqITWx9E',\n",
    "        'W2': '1jHWRjwkahxpA5T_BWBRaMQ4q9kyg1l0gGz42pC6-dxI',\n",
    "        'W3': '1C-Yyc17WFWScC5eu5WttQc8P8vCFuLvh8MqlBKiwF8c',\n",
    "        'W4': '1J0xqeC05H1RVPSERi8fCXWUTGJ4iH3SI0w59BoFh_KU',\n",
    "        'W5': '1T9jbfP1iapNLS94QZMiYw5K6LrZoP01Qf1jvTWpvdkU',\n",
    "        'W6': '1G0chmXUmWC-lrZLg9ToQTGCdQmnbP0DA204bIKJn9yc',\n",
    "    },\n",
    "    'sun': {\n",
    "        'W1': '1R-bT3RMu41cx-fnac3mNdb3OT_kb6vof1eMdCbU8_jM',\n",
    "        'W2': '1ugtKZhO4jLtxW_yEwrrPXZtry2pLaP-6QgiIHKldl5E',\n",
    "        'W3': '1OzP1XwzU3c-rNXyqxU3JKrrXHeXzSu3D6FIcfym4fHE',\n",
    "        'W4': '1dNwW9dL4YPBEypUHQ6_-Dse8XL851W0WUiCBb28hRBQ',   \n",
    "        'W5': '16wXGP08nESdLg4am4wfngeMNbK81IJAo3p0udg_iVlU',\n",
    "        'W6': '1ZQEBOPGAlc6f2IUwavEKpPHY7dQxV4lN5iSQm1WHnX4',\n",
    "    }\n",
    "}\n",
    "id_to_key_task2 = {\n",
    "    'ind': {\n",
    "        'W1': '1Wa33qUjeB0pq1QI87jUqHTXlQ88ADCxAFp77vFAhSVU',\n",
    "        'W2': '1FbYeTu3ZK4vBLoPVpJqCFB8Rj6yzazYRpxRtmPXXf-k',\n",
    "        'W3': '1UysOeI1QnU8sNXqwQ7FGnULvKCjt8Tm6eoFEdYeQ0xY',\n",
    "        'W4': '1lKIAWvs9D8JoyNrZJzB6pU4KVtfWstH3tOEfM9dZMDc',\n",
    "        'W5': '1nQsQPAoxeRr9QzybjrkpTn5-IuBBCByMNN8txkUVV4w',\n",
    "        'W6': '1SCV9OBxvHwxQ31t6GFirO6et-raMbMpJdfLjn1_HsgU',\n",
    "    },\n",
    "    'sun': {\n",
    "        'W1': '1-FLTsgge53Wgb3HmIlM-oCOWow4_kLEJ0bey8MaMxVI',\n",
    "        'W2': '1-WLiRHFXlD5BawHdBkI2kLSlLttBXU4ufnTwLB8pufM',\n",
    "        'W3': '1EVv6ktg-6ZC5e9UBFvPIVrZI0T2WAbx3OHau_T-OgSE',\n",
    "        'W4': '1XyXhn_R3VuNcsmHCmCEwojFM1hUPGhQe6FDrfo3ALds',\n",
    "        'W5': '1YsreB2g0AeDbiFOIu2JOUmbAkwugBRaaf8SMUA2mrg0',\n",
    "        'W6': '1oU4K52UaKJT3EEvDdOs8o4tD97Wxl4SKSFQK193w2bQ',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response history not found. Initializing new one...\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.organization = os.environ['OPENAI_UILAB_KEY']\n",
    "model_name = \"gpt-4\"\n",
    "resp_history_filename = f\"{model_name}_history_231106.csv\"\n",
    "resp_history_path = Path(resp_history_filename)\n",
    "if resp_history_path.is_file():\n",
    "    print(\"Response history found!\")\n",
    "    resp_history_df = pd.read_csv(resp_history_filename)\n",
    "    response_history = dict(zip(resp_history_df.prompt, resp_history_df.response))\n",
    "else:\n",
    "    print(\"Response history not found. Initializing new one...\")\n",
    "    response_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_chat_completion(input_prompt, model_name, resp_num=1):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': input_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        n=resp_num\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_prompt(question_prompt):\n",
    "    end_prompt = \"Give only one answer that most likely to be the correct answer with a prefix that says \\\"Answer:\\\" follows by the option letter. For example:\\nAnswer: Z\"\n",
    "    return f\"{question_prompt}\\n\\n{end_prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_answer(input_prompt, model_name, resp_num=1):\n",
    "    if input_prompt in response_history:\n",
    "        return response_history[input_prompt]\n",
    "    \n",
    "    resp = get_openai_chat_completion(input_prompt, model_name, resp_num)\n",
    "    answer = resp.choices[0].message.content.strip().upper()\n",
    "    answer_cleaned = answer.replace('ANSWER: ', '')\n",
    "    if '. ' in answer_cleaned:\n",
    "        answer_cleaned = answer_cleaned.split('. ')[0]\n",
    "\n",
    "    if len(answer_cleaned) > 1:\n",
    "        print('Answer len > 1, retry...')\n",
    "        print('Answer before:', answer_cleaned)\n",
    "        resp = get_openai_chat_completion(input_prompt, model_name, resp_num)\n",
    "        answer = resp.choices[0].message.content.strip().upper()\n",
    "        answer_cleaned = answer.replace('ANSWER: ', '')\n",
    "        if '. ' in answer_cleaned:\n",
    "            answer_cleaned = answer_cleaned.split('. ')[0]\n",
    "        print('Answer after:', answer_cleaned)\n",
    "\n",
    "    response_history[input_prompt] = answer_cleaned\n",
    "    resp_history_df = pd.DataFrame({'prompt': response_history.keys(), 'response': response_history.values()})\n",
    "    resp_history_df.to_csv(resp_history_filename, index=False)\n",
    "\n",
    "    return answer_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing question prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing question prompt: 100%|██████████| 6/6 [00:15<00:00,  2.66s/it]\n",
      "Processing question prompt: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "answers_letters = ['A', 'B', 'C', 'D', 'E']\n",
    "prompts_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    prompts_by_id = {}\n",
    "    for ref_id in tqdm(workers_ids, desc='Processing question prompt'):\n",
    "        sh_task1 = client.open_by_key(id_to_key_task1[lang][ref_id])\n",
    "        wks_task1 = sh_task1.worksheet('title', 'Data')\n",
    "        \n",
    "        question_col_num = 4 if lang == 'ind' else 5\n",
    "        questions = [q for q in wks_task1.get_col(question_col_num)[1:] if q != '']\n",
    "        \n",
    "        options_col_num = 5 if lang == 'ind' else 6\n",
    "        options = wks_task1.get_col(options_col_num)[1:]\n",
    "        options_group, options_buffer = [], []\n",
    "        for option in options:\n",
    "            options_buffer.append(option)\n",
    "            if len(options_buffer) == 5:\n",
    "                options_group.append(options_buffer)\n",
    "                options_buffer = []\n",
    "        \n",
    "        gold_col_num  = 6 if lang == 'ind' else 7\n",
    "        gold = wks_task1.get_col(gold_col_num)[1:]\n",
    "        gold_group, gold_buffer = [], []\n",
    "        for ans in gold:\n",
    "            gold_buffer.append(ans)\n",
    "            if len(gold_buffer) == 5:\n",
    "                gold_group.append(gold_buffer)\n",
    "                gold_buffer = []\n",
    "        \n",
    "        prompts = []\n",
    "        for q, o, g in zip(questions, options_group, gold_group):\n",
    "            question_prompt = q\n",
    "            for o_item in o:\n",
    "                question_prompt += f\"\\n{o_item}\"\n",
    "            answer = answers_letters[g.index('TRUE')]\n",
    "            prompts.append({\n",
    "                'question_prompt': question_prompt,\n",
    "                'answer': answer\n",
    "            })\n",
    "\n",
    "        prompts_by_id[ref_id] = prompts\n",
    "    \n",
    "    prompts_by_lang[lang] = prompts_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 250/250 [00:00<00:00, 293472.15it/s]\n",
      "Processing W2: 100%|██████████| 250/250 [00:00<00:00, 296626.87it/s]\n",
      "Processing W3: 100%|██████████| 250/250 [00:00<00:00, 316217.13it/s]\n",
      "Processing W4: 100%|██████████| 250/250 [00:00<00:00, 244594.36it/s]\n",
      "Processing W5: 100%|██████████| 250/250 [00:00<00:00, 255438.73it/s]\n",
      "Processing W6: 100%|██████████| 250/250 [00:00<00:00, 230811.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: sun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 250/250 [00:00<00:00, 230709.79it/s]\n",
      "Processing W2: 100%|██████████| 250/250 [00:00<00:00, 231575.97it/s]\n",
      "Processing W3: 100%|██████████| 250/250 [00:00<00:00, 235264.98it/s]\n",
      "Processing W4: 100%|██████████| 250/250 [00:00<00:00, 226425.39it/s]\n",
      "Processing W5: 100%|██████████| 250/250 [00:00<00:00, 227852.24it/s]\n",
      "Processing W6: 100%|██████████| 250/250 [01:23<00:00,  2.99it/s] \n"
     ]
    }
   ],
   "source": [
    "answers_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    answers_by_id = {}\n",
    "    prompts_by_id = prompts_by_lang[lang]\n",
    "    print('Language:', lang)\n",
    "    for ref_id in workers_ids:\n",
    "        answers = []\n",
    "        for prompt_item in tqdm(prompts_by_id[ref_id], desc=f\"Processing {ref_id}\"):\n",
    "            input_prompt = get_input_prompt(prompt_item['question_prompt'])\n",
    "            model_pred = get_openai_answer(input_prompt, model_name, resp_num=1)\n",
    "            answers.append(model_pred)\n",
    "        answers_by_id[ref_id] = answers\n",
    "    answers_by_lang[lang] = answers_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_num_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    conflict_num_by_id = {}\n",
    "    for ref_id in workers_ids:\n",
    "        conflict_num = 0\n",
    "        for pred, gold in zip(answers_by_lang[lang][ref_id], prompts_by_lang[lang][ref_id]):\n",
    "            if pred != gold['answer']:\n",
    "                conflict_num += 1\n",
    "        conflict_num_by_id[ref_id] = conflict_num\n",
    "    conflict_num_by_lang[lang] = conflict_num_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': {'W1': 35, 'W2': 28, 'W3': 22, 'W4': 23, 'W5': 13, 'W6': 13},\n",
       " 'sun': {'W1': 68, 'W2': 57, 'W3': 60, 'W4': 61, 'W5': 76, 'W6': 71}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_num_by_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze anno conflict num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in ['ind', 'sun']:\n",
    "    # Get gold answer\n",
    "    gold_ans = {}\n",
    "    for ref_id in tqdm(workers_ids):\n",
    "        sh_task1 = client.open_by_key(id_to_key_task1[lang][ref_id])\n",
    "        wks_task1 = sh_task1.worksheet('title', 'Data')\n",
    "        gold_col_num  = 6 if lang == 'ind' else 7\n",
    "        gold_ans[ref_id] = wks_task1.get_col(gold_col_num)[1:]\n",
    "\n",
    "    conflict_data = {}\n",
    "    for pred_id in tqdm(workers_ids):\n",
    "        all_conflict_counts = []\n",
    "        sh_pred = client.open_by_key(id_to_key_task2[lang][pred_id])\n",
    "        for ref_id in workers_ids:\n",
    "            if pred_id == ref_id:\n",
    "                all_conflict_counts.append(0)\n",
    "            else:\n",
    "                wks_pred = sh_pred.worksheet('title', ref_id)\n",
    "\n",
    "                # Get answers\n",
    "                ans_col_num  = 6 if lang == 'ind' else 7\n",
    "                pred_ans = wks_pred.get_col(ans_col_num)[1:]\n",
    "                \n",
    "                # Get conflict status\n",
    "                stat, stat_buffer = [], []\n",
    "                for pred, gold in zip(pred_ans, gold_ans[ref_id]):\n",
    "\n",
    "                    stat_buffer.append('OK' if pred == gold else 'CONFLICT')\n",
    "                    if len(stat_buffer) == 5:\n",
    "                        stat.append('CONFLICT' if 'CONFLICT' in stat_buffer else 'OK')\n",
    "                        stat_buffer = []\n",
    "\n",
    "                ok_count, conflict_count = stat.count('OK'), stat.count('CONFLICT')\n",
    "                if ok_count + conflict_count != 250:\n",
    "                    print(pred_id, ref_id, ok_count, conflict_count)\n",
    "                assert ok_count + conflict_count == 250\n",
    "                all_conflict_counts.append(conflict_count)\n",
    "        conflict_data[pred_id] = all_conflict_counts\n",
    "\n",
    "    conflict_df = pd.DataFrame.from_dict(conflict_data, orient='index', columns=workers_ids)\n",
    "    print('Conflict data for', lang)\n",
    "    print(conflict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
