{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pygsheets\n",
    "import pandas as pd\n",
    "import openai\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize sheet credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pygsheets.authorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers_ids = ['W1', 'W2', 'W3', 'W4', 'W5', 'W6']\n",
    "id_to_key_task1 = {\n",
    "    'ind': {\n",
    "        'W1': '14dAiIsBLxBUHzXgFDznMjSXCJmFY6qnIWOADqITWx9E',\n",
    "        'W2': '1jHWRjwkahxpA5T_BWBRaMQ4q9kyg1l0gGz42pC6-dxI',\n",
    "        'W3': '1C-Yyc17WFWScC5eu5WttQc8P8vCFuLvh8MqlBKiwF8c',\n",
    "        'W4': '1J0xqeC05H1RVPSERi8fCXWUTGJ4iH3SI0w59BoFh_KU',\n",
    "        'W5': '1T9jbfP1iapNLS94QZMiYw5K6LrZoP01Qf1jvTWpvdkU',\n",
    "        'W6': '1G0chmXUmWC-lrZLg9ToQTGCdQmnbP0DA204bIKJn9yc',\n",
    "    },\n",
    "    'sun': {\n",
    "        'W1': '1R-bT3RMu41cx-fnac3mNdb3OT_kb6vof1eMdCbU8_jM',\n",
    "        'W2': '1ugtKZhO4jLtxW_yEwrrPXZtry2pLaP-6QgiIHKldl5E',\n",
    "        'W3': '1OzP1XwzU3c-rNXyqxU3JKrrXHeXzSu3D6FIcfym4fHE',\n",
    "        'W4': '1dNwW9dL4YPBEypUHQ6_-Dse8XL851W0WUiCBb28hRBQ',   \n",
    "        'W5': '16wXGP08nESdLg4am4wfngeMNbK81IJAo3p0udg_iVlU',\n",
    "        'W6': '1ZQEBOPGAlc6f2IUwavEKpPHY7dQxV4lN5iSQm1WHnX4',\n",
    "    }\n",
    "}\n",
    "id_to_key_task2 = {\n",
    "    'ind': {\n",
    "        'W1': '1Wa33qUjeB0pq1QI87jUqHTXlQ88ADCxAFp77vFAhSVU',\n",
    "        'W2': '1FbYeTu3ZK4vBLoPVpJqCFB8Rj6yzazYRpxRtmPXXf-k',\n",
    "        'W3': '1UysOeI1QnU8sNXqwQ7FGnULvKCjt8Tm6eoFEdYeQ0xY',\n",
    "        'W4': '1lKIAWvs9D8JoyNrZJzB6pU4KVtfWstH3tOEfM9dZMDc',\n",
    "        'W5': '1nQsQPAoxeRr9QzybjrkpTn5-IuBBCByMNN8txkUVV4w',\n",
    "        'W6': '1SCV9OBxvHwxQ31t6GFirO6et-raMbMpJdfLjn1_HsgU',\n",
    "    },\n",
    "    'sun': {\n",
    "        'W1': '1-FLTsgge53Wgb3HmIlM-oCOWow4_kLEJ0bey8MaMxVI',\n",
    "        'W2': '1-WLiRHFXlD5BawHdBkI2kLSlLttBXU4ufnTwLB8pufM',\n",
    "        'W3': '1EVv6ktg-6ZC5e9UBFvPIVrZI0T2WAbx3OHau_T-OgSE',\n",
    "        'W4': '1XyXhn_R3VuNcsmHCmCEwojFM1hUPGhQe6FDrfo3ALds',\n",
    "        'W5': '1YsreB2g0AeDbiFOIu2JOUmbAkwugBRaaf8SMUA2mrg0',\n",
    "        'W6': '1oU4K52UaKJT3EEvDdOs8o4tD97Wxl4SKSFQK193w2bQ',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data (with commonsense QA format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ind: 100%|██████████| 6/6 [00:18<00:00,  3.07s/it]\n",
      "Processing sun: 100%|██████████| 6/6 [02:08<00:00, 21.38s/it]\n"
     ]
    }
   ],
   "source": [
    "answers_letters = ['A', 'B', 'C', 'D', 'E']\n",
    "cat_id_to_en = {\n",
    "    'Kuliner': 'culinary',\n",
    "    'Tempat': 'place',\n",
    "    'Budaya': 'culture',\n",
    "    'Sejarah': 'history',\n",
    "    'Aktivitas': 'activity',\n",
    "}\n",
    "data_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    data_by_id = {}\n",
    "    for ref_id in tqdm(workers_ids, desc=f'Processing {lang}'):\n",
    "        sh_task1 = client.open_by_key(id_to_key_task1[lang][ref_id])\n",
    "        wks_task1 = sh_task1.worksheet('title', 'Data')\n",
    "\n",
    "        categories = [c for c in wks_task1.get_col(2)[1:] if c != '']\n",
    "        question_concepts = [c for c in wks_task1.get_col(3)[1:] if c != '']\n",
    "        question_concepts_trans = [c for c in wks_task1.get_col(4)[1:] if c != ''] if lang == \"sun\" else []\n",
    "        \n",
    "        question_col_num = 4 if lang == 'ind' else 5\n",
    "        questions = [q for q in wks_task1.get_col(question_col_num)[1:] if q != '']\n",
    "        \n",
    "        options_col_num = 5 if lang == 'ind' else 6\n",
    "        options = wks_task1.get_col(options_col_num)[1:]\n",
    "        options_group, options_buffer = [], []\n",
    "        for option in options:\n",
    "            options_buffer.append(option)\n",
    "            if len(options_buffer) == 5:\n",
    "                options_group.append(options_buffer)\n",
    "                options_buffer = []\n",
    "        \n",
    "        gold_col_num  = 6 if lang == 'ind' else 7\n",
    "        gold = wks_task1.get_col(gold_col_num)[1:]\n",
    "        gold_group, gold_buffer = [], []\n",
    "        for ans in gold:\n",
    "            gold_buffer.append(ans)\n",
    "            if len(gold_buffer) == 5:\n",
    "                gold_group.append(gold_buffer)\n",
    "                gold_buffer = []\n",
    "        \n",
    "        data = []\n",
    "        for i in range(len(questions)):\n",
    "            answer_texts = [o[3:] for o in options_group[i]]\n",
    "            answer = answers_letters[gold_group[i].index('TRUE')]\n",
    "            data.append({\n",
    "                'category': cat_id_to_en[categories[i]],\n",
    "                'question_concepts': question_concepts[i] if lang == 'ind' else question_concepts_trans[i],\n",
    "                'question': questions[i],\n",
    "                'choices': {\n",
    "                    'label': answers_letters,\n",
    "                    'text': answer_texts\n",
    "                },\n",
    "                'answer_creator': answer,\n",
    "                'answer_majority': '',\n",
    "                'answers': {},\n",
    "                'answers_uncertainty': {},\n",
    "                'question_ambiguity': {},\n",
    "                'option_ambiguity': {},\n",
    "                'reason': {}\n",
    "            })\n",
    "\n",
    "        data_by_id[ref_id] = data\n",
    "    \n",
    "    data_by_lang[lang] = data_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 6/6 [00:09<00:00,  1.62s/it]\n",
      "Processing W2: 100%|██████████| 6/6 [00:11<00:00,  1.84s/it]\n",
      "Processing W3: 100%|██████████| 6/6 [01:52<00:00, 18.77s/it]\n",
      "Processing W4: 100%|██████████| 6/6 [00:09<00:00,  1.61s/it]\n",
      "Processing W5: 100%|██████████| 6/6 [00:12<00:00,  2.08s/it]\n",
      "Processing W6: 100%|██████████| 6/6 [00:09<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "Processing W2: 100%|██████████| 6/6 [02:14<00:00, 22.39s/it]\n",
      "Processing W3: 100%|██████████| 6/6 [00:09<00:00,  1.54s/it]\n",
      "Processing W4: 100%|██████████| 6/6 [00:10<00:00,  1.68s/it]\n",
      "Processing W5: 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]\n",
      "Processing W6: 100%|██████████| 6/6 [00:12<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "for lang in ['ind', 'sun']:\n",
    "    print(f'Processing {lang}')\n",
    "    for ref_id in workers_ids:\n",
    "        sh_task2 = client.open_by_key(id_to_key_task2[lang][ref_id])\n",
    "        for pred_id in tqdm(workers_ids, desc=f'Processing {ref_id}'):\n",
    "            if pred_id == ref_id:\n",
    "                continue\n",
    "            wks_task2 = sh_task2.worksheet('title', pred_id)\n",
    "\n",
    "            q_ambiguity_col_num = 8 if lang == 'ind' else 9\n",
    "            q_ambiguity = [q for q in wks_task2.get_col(q_ambiguity_col_num)[1:] if q != '']\n",
    "\n",
    "            uncertainty_col_num = 10 if lang == 'ind' else 11\n",
    "            uncertainty = [q for q in wks_task2.get_col(uncertainty_col_num)[1:] if q != '']\n",
    "\n",
    "            reason_col_num = 11 if lang == 'ind' else 12\n",
    "            reasons = wks_task2.get_col(reason_col_num)[1:]\n",
    "            reason_single, reason_buffer = [], []\n",
    "            for reason in reasons:\n",
    "                reason_buffer.append(reason)\n",
    "                if len(reason_buffer) == 5:\n",
    "                    reason_single.append(reason_buffer[0])\n",
    "                    reason_buffer = []\n",
    "\n",
    "            answer_col_num = 6 if lang == 'ind' else 7\n",
    "            answers = wks_task2.get_col(answer_col_num)[1:]\n",
    "            answers_single, answers_buffer = [], []\n",
    "            for answer in answers:\n",
    "                answers_buffer.append(answer)\n",
    "                if len(answers_buffer) == 5:\n",
    "                    answers_single.append(answers_letters[answers_buffer.index('TRUE')])\n",
    "                    answers_buffer = []\n",
    "\n",
    "            options_col_num = 9 if lang == 'ind' else 10\n",
    "            options = wks_task2.get_col(options_col_num)[1:]\n",
    "            options_group, options_buffer = [], []\n",
    "            for option in options:\n",
    "                options_buffer.append(option)\n",
    "                if len(options_buffer) == 5:\n",
    "                    options_group.append(options_buffer)\n",
    "                    options_buffer = []\n",
    "            \n",
    "            for i in range(len(q_ambiguity)):\n",
    "                data_by_lang[lang][pred_id][i]['answers'][ref_id] = answers_single[i]\n",
    "                data_by_lang[lang][pred_id][i]['answers_uncertainty'][ref_id] = uncertainty[i]\n",
    "                data_by_lang[lang][pred_id][i]['question_ambiguity'][ref_id] = q_ambiguity[i]\n",
    "                data_by_lang[lang][pred_id][i]['option_ambiguity'][ref_id] = options_group[i]\n",
    "                data_by_lang[lang][pred_id][i]['reason'][ref_id] = reason_single[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_element(lst):\n",
    "    counts = Counter(lst)\n",
    "    majority = max(counts, key=counts.get)\n",
    "    return majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing majority question: 100%|██████████| 6/6 [00:00<00:00, 498.01it/s]\n",
      "Processing majority question: 100%|██████████| 6/6 [00:00<00:00, 705.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data_by_lang_majority = {'ind': {}, 'sun': {}}\n",
    "for lang in ['ind', 'sun']:\n",
    "    for ref_id in tqdm(workers_ids, desc='Processing majority question'):\n",
    "        data_by_id = []\n",
    "        for item in data_by_lang[lang][ref_id]:\n",
    "            item['answer_majority'] = get_majority_element(list(item['answers'].values()))\n",
    "            data_by_id.append(item)\n",
    "        data_by_lang_majority[lang][ref_id] = data_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'aduk',\n",
       " 'question': 'Apa yang biasanya digunakan untuk mengaduk kopi?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Sedotan', 'Bungkus kopi', 'Garpu', 'Sumpit', 'Sendok']},\n",
       " 'answer_creator': 'C',\n",
       " 'answer_majority': 'E',\n",
       " 'answers': {'W2': 'E', 'W3': 'E', 'W4': 'E', 'W5': 'A', 'W6': 'E'},\n",
       " 'answers_uncertainty': {'W2': 'certain',\n",
       "  'W3': 'certain',\n",
       "  'W4': 'certain',\n",
       "  'W5': 'certain',\n",
       "  'W6': 'certain'},\n",
       " 'question_ambiguity': {'W2': 'clear',\n",
       "  'W3': 'clear',\n",
       "  'W4': 'clear',\n",
       "  'W5': 'clear',\n",
       "  'W6': 'clear'},\n",
       " 'option_ambiguity': {'W2': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W3': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W4': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W5': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W6': ['clear', 'clear', 'clear', 'clear', 'clear']},\n",
       " 'reason': {'W2': '', 'W3': '', 'W4': '', 'W5': '', 'W6': ''}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lang['ind']['W1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'adab dahar',\n",
       " 'question': 'Dihandap ieu anu termasuk kana adab dahar anu umum di daerah Sunda nyaeta?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Nganggo panangan kenca',\n",
       "   'Nyandak kaemaman anu tebih',\n",
       "   'Dahar bari nyarios',\n",
       "   'Nganggo panangan katuhu',\n",
       "   'Dahar bari diuk']},\n",
       " 'answer_creator': 'D',\n",
       " 'answer_majority': 'D',\n",
       " 'answers': {'W2': 'D', 'W3': 'D', 'W4': 'D', 'W5': 'D', 'W6': 'D'},\n",
       " 'answers_uncertainty': {'W2': 'certain',\n",
       "  'W3': 'certain',\n",
       "  'W4': 'certain',\n",
       "  'W5': 'certain',\n",
       "  'W6': 'certain'},\n",
       " 'question_ambiguity': {'W2': 'clear',\n",
       "  'W3': 'clear',\n",
       "  'W4': 'clear',\n",
       "  'W5': 'clear',\n",
       "  'W6': 'clear'},\n",
       " 'option_ambiguity': {'W2': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W3': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W4': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W5': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W6': ['clear', 'clear', 'clear', 'clear', 'clear']},\n",
       " 'reason': {'W2': '', 'W3': '', 'W4': '', 'W5': '', 'W6': ''}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lang['sun']['W1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the dataset\n",
    "for lang in ['ind', 'sun']:\n",
    "    with open(f'../../dataset/v2_human/raw_{lang}.json', 'w', encoding='utf-8') as fp:\n",
    "        json.dump(data_by_lang[lang], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_certainty_based_on_reason(reason, certainty):\n",
    "    reason = reason.lower()\n",
    "    pattern = r\"\\[uncertai(?:n|nty)[^\\]]*\\].*?(?=\\[|$)\"\n",
    "    matches = re.findall(pattern, reason)\n",
    "    if matches:\n",
    "        reason = ''.join(matches).strip()\n",
    "    \n",
    "    if 'googl' in reason:\n",
    "        if any(word in reason for word in ['tidak ada', 'susah', 'sulit', 'belum menemukan']):\n",
    "            return 'uncertain'\n",
    "        else:\n",
    "            return 'certain'\n",
    "    else:\n",
    "        return certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering question: 100%|██████████| 6/6 [00:00<00:00, 275.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguous question:\n",
      "{'category': 'place', 'question_concepts': 'pulau', 'question': 'Pulau yang terkenal akan kotanya yang besar adalah?', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['Pulau Bali', 'Pulau Jawa', 'Pulau Lombok', 'Pulau Sumatera', 'Nusa Tenggara Barat']}, 'answer_creator': 'B', 'answer_majority': 'B', 'answers': {'W1': 'B', 'W2': 'B', 'W3': 'B', 'W4': 'B', 'W5': 'B'}, 'answers_uncertainty': {'W1': 'certain', 'W2': 'certain', 'W3': 'uncertain', 'W4': 'certain', 'W5': 'uncertain'}, 'question_ambiguity': {'W1': 'ambiguous', 'W2': 'clear', 'W3': 'ambiguous', 'W4': 'clear', 'W5': 'ambiguous'}, 'option_ambiguity': {'W1': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W2': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W3': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W4': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W5': ['clear', 'ambiguous', 'clear', 'ambiguous', 'clear']}, 'reason': {'W1': '[ambiguous] besar secara ukuran lokasi antarkota di pulau-pulau lainnya atau antara pulau yang bersangkutan dengan kota di pulau tersebut. jawabannya akan sangat berbeda.', 'W2': '', 'W3': '[Question Ambiguous] Tidak bisa memahami pertanyaan apakah yang dimaksud pulau dengan kota terbesar atau pulau dengan banyak kota besar atau pulau yang terdiri dari satu kota besar\\n[Uncertain] Meragukan antara B/C/D karena kurang pengetahuan. Dibantu googling tapi masih tidak tahu jawabannya', 'W4': '', 'W5': '[question] ambigu karena besar berdasarkan apa? ukuran atau kemajuan kotanya? \\n\\n[options] ambigu karena opsi A jika dilihat dari kemajuannya, opsi D jika dari ukurannya\\n\\n[uncertain] tidak yakin karena ada lebih dari satu jawaban yang potensial'}}\n",
      "Uncertain question:\n",
      "{'category': 'history', 'question_concepts': 'proses', 'question': 'Proses Indonesia sampai mencapai kemerdekaannya memerlukan waktu sekitar berapa lama?', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['700 tahun', '450 tahun', '120 tahun', '7 tahun', '135 tahun']}, 'answer_creator': 'B', 'answer_majority': 'B', 'answers': {'W1': 'B', 'W2': 'B', 'W3': 'B', 'W4': 'B', 'W5': 'B'}, 'answers_uncertainty': {'W1': 'uncertain', 'W2': 'uncertain', 'W3': 'uncertain', 'W4': 'uncertain', 'W5': 'uncertain'}, 'question_ambiguity': {'W1': 'clear', 'W2': 'clear', 'W3': 'ambiguous', 'W4': 'clear', 'W5': 'ambiguous'}, 'option_ambiguity': {'W1': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W2': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W3': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W4': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W5': ['clear', 'clear', 'clear', 'clear', 'clear']}, 'reason': {'W1': '[uncertain] tidak ada jawaban yang tepat, namun B adalah pengetahuan keliru yang selama ini diajarkan di sekolah-sekolah.', 'W2': '[Uncertain] Jawaban sulit divalidasi dengan penelusuran Google, pilihan jawaban 450 tahun karena paling dekat dengan durasi kolonialisasi paling lama yaitu ±350 tahun.', 'W3': '[Question Ambiguous] Pertanyaannya tidak umum didengar dan informasinya tidak umum diajarkan di sekolah, apakah maksudnya dari penjajahan portugis atau kolonialisme setelah VOC atau yang lain\\n[Uncertain] Saat googling tidak ada informasinya tapi mungkin secara hitung-hitungan dari jaman portugis yang tepat adalah 450 tahun', 'W4': '[Uncertain] Hasil penelusuran Google: namun belum menemukan jawaban yang pasti', 'W5': '[question] ambigu karena perhitungannya sejak kapan? \\n\\n[option] ambigu karena seperti tidak ada jawaban benar \\n\\n[uncertain] tidak yakin karena keterbatasan pengetahuan dan validasi google'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering question: 100%|██████████| 6/6 [00:00<00:00, 299.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertain question:\n",
      "{'category': 'culture', 'question_concepts': 'Dayak', 'question': 'Naon bagian ti kabudayaan Dayak nu loba dijelaskeun di buku sakola?', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['Imah tradisionalna', 'Cara hirupna', 'Pakean tradisionalna', 'Cara urang Dayak ngaranan budak', 'Cara nyawahna']}, 'answer_creator': 'C', 'answer_majority': 'C', 'answers': {'W1': 'C', 'W3': 'A', 'W4': 'C', 'W5': 'B', 'W6': 'C'}, 'answers_uncertainty': {'W1': 'uncertain', 'W3': 'uncertain', 'W4': 'certain', 'W5': 'uncertain', 'W6': 'uncertain'}, 'question_ambiguity': {'W1': 'clear', 'W3': 'clear', 'W4': 'clear', 'W5': 'clear', 'W6': 'clear'}, 'option_ambiguity': {'W1': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W3': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W4': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W5': ['clear', 'clear', 'clear', 'clear', 'clear'], 'W6': ['clear', 'clear', 'clear', 'clear', 'clear']}, 'reason': {'W1': '[Uncertain] Tidak yakin saat mengisi jawaban karena tidak yakin dengan jawaban distraktor', 'W3': '[Uncertain] Tidak yakin antara pakaian atau cara hidup', 'W4': '', 'W5': '[uncertain] tidak yakin dengan jawabannya', 'W6': '[uncertain] menurut anotator opsi A, B, dan C setara'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_by_lang, num_q_ambiguous_by_lang, num_op_ambiguous_by_lang, num_uncertain_by_lang, filtered_data_by_lang = {}, {}, {}, {}, {}\n",
    "workers_ids = ['W1', 'W2', 'W3', 'W4', 'W5', 'W6']\n",
    "for lang in ['ind', 'sun']:\n",
    "    with open(f'../../dataset/v2_human/raw_{lang}.json', encoding='utf-8') as fp:\n",
    "        data_by_lang[lang] = json.load(fp)\n",
    "    \n",
    "    filtered_data = []\n",
    "    num_q_ambiguous_by_wid, num_op_ambiguous_by_wid, num_uncertain_by_wid = {}, {}, {}\n",
    "    for ref_id in tqdm(workers_ids, desc='Filtering question'):\n",
    "        q_ambiguous_num, op_ambiguous_num, uncertain_num = 0, 0, 0\n",
    "        for item in data_by_lang[lang][ref_id]:\n",
    "            is_q_ambiguous = list(item['question_ambiguity'].values()).count('ambiguous') >= 3\n",
    "            \n",
    "            op_ambiguity = list(item['option_ambiguity'].values())\n",
    "            op_ambiguity_grouped = []\n",
    "            for row in zip(*op_ambiguity):\n",
    "                op_ambiguity_grouped.append(list(row).count('ambiguous') >= 3)\n",
    "            is_op_ambiguous = op_ambiguity_grouped.count(True) >= 3\n",
    "\n",
    "            uncertainty_grouped = []\n",
    "            for ans_un, reason in zip(list(item['answers_uncertainty'].values()), list(item['reason'].values())):\n",
    "                if ans_un == 'certain':\n",
    "                    uncertainty_grouped.append('certain')\n",
    "                else:\n",
    "                    uncertainty_grouped.append(get_certainty_based_on_reason(reason, ans_un))\n",
    "            is_uncertain = uncertainty_grouped.count('uncertain') >= 4\n",
    "\n",
    "            if not is_q_ambiguous and not is_op_ambiguous and not is_uncertain:\n",
    "                filtered_data.append(item)\n",
    "            else:\n",
    "                if is_q_ambiguous:\n",
    "                    q_ambiguous_num += 1\n",
    "                    print('Ambiguous question:')\n",
    "                    print(item)\n",
    "                elif is_op_ambiguous:\n",
    "                    op_ambiguous_num += 1\n",
    "                elif is_uncertain:\n",
    "                    uncertain_num += 1\n",
    "                    print('Uncertain question:')\n",
    "                    print(item)\n",
    "\n",
    "        num_q_ambiguous_by_wid[ref_id] = q_ambiguous_num\n",
    "        num_op_ambiguous_by_wid[ref_id] = op_ambiguous_num\n",
    "        num_uncertain_by_wid[ref_id] = uncertain_num\n",
    "\n",
    "    filtered_data_by_lang[lang] = filtered_data\n",
    "    num_q_ambiguous_by_lang[lang] = num_q_ambiguous_by_wid\n",
    "    num_op_ambiguous_by_lang[lang] = num_op_ambiguous_by_wid\n",
    "    num_uncertain_by_lang[lang] = num_uncertain_by_wid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1498, 1499)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data_by_lang['ind']), len(filtered_data_by_lang['sun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': {'W1': 0, 'W2': 0, 'W3': 0, 'W4': 0, 'W5': 0, 'W6': 1},\n",
       " 'sun': {'W1': 0, 'W2': 0, 'W3': 0, 'W4': 0, 'W5': 0, 'W6': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_q_ambiguous_by_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': {'W1': 0, 'W2': 0, 'W3': 0, 'W4': 0, 'W5': 0, 'W6': 0},\n",
       " 'sun': {'W1': 0, 'W2': 0, 'W3': 0, 'W4': 0, 'W5': 0, 'W6': 0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_op_ambiguous_by_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': {'W1': 0, 'W2': 0, 'W3': 0, 'W4': 0, 'W5': 0, 'W6': 1},\n",
       " 'sun': {'W1': 0, 'W2': 1, 'W3': 0, 'W4': 0, 'W5': 0, 'W6': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_uncertain_by_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'aduk',\n",
       " 'question': 'Apa yang biasanya digunakan untuk mengaduk kopi?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Sedotan', 'Bungkus kopi', 'Garpu', 'Sumpit', 'Sendok']},\n",
       " 'answer_creator': 'C',\n",
       " 'answer_majority': 'E',\n",
       " 'answers': {'W2': 'E', 'W3': 'E', 'W4': 'E', 'W5': 'A', 'W6': 'E'},\n",
       " 'answers_uncertainty': {'W2': 'certain',\n",
       "  'W3': 'certain',\n",
       "  'W4': 'certain',\n",
       "  'W5': 'certain',\n",
       "  'W6': 'certain'},\n",
       " 'question_ambiguity': {'W2': 'clear',\n",
       "  'W3': 'clear',\n",
       "  'W4': 'clear',\n",
       "  'W5': 'clear',\n",
       "  'W6': 'clear'},\n",
       " 'option_ambiguity': {'W2': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W3': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W4': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W5': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W6': ['clear', 'clear', 'clear', 'clear', 'clear']},\n",
       " 'reason': {'W2': '', 'W3': '', 'W4': '', 'W5': '', 'W6': ''}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_by_lang['ind'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the dataset\n",
    "for lang in ['ind', 'sun']:\n",
    "    with open(f'../../dataset/v2_human/filtered_{lang}.json', 'w', encoding='utf-8') as fp:\n",
    "        json.dump(filtered_data_by_lang[lang], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing question prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_letters = ['A', 'B', 'C', 'D', 'E']\n",
    "prompts_by_lang, data_by_lang = {}, {}\n",
    "mode = 'v2_filtered'\n",
    "if mode in ['v1', 'v2_filtered']:\n",
    "    workers_ids = ['W1']\n",
    "else:\n",
    "    workers_ids = ['W1', 'W2', 'W3', 'W4', 'W5', 'W6']\n",
    "for lang in ['ind', 'sun']:\n",
    "    if mode == 'v1':\n",
    "        input_filename = f'../../dataset/v1_synthetic/filtered_both_test_{lang}.json'\n",
    "    elif mode == 'v2_raw':\n",
    "        input_filename = f'../../dataset/v2_human/raw_{lang}.json'\n",
    "    elif mode == 'v2_filtered':\n",
    "        input_filename = f'../../dataset/v2_human/filtered_{lang}.json'\n",
    "    \n",
    "    with open(input_filename, encoding='utf-8') as fp:\n",
    "        data_by_lang[lang] = json.load(fp)\n",
    "    \n",
    "    if mode == 'v1':\n",
    "        prompts = []\n",
    "        for item in data_by_lang[lang]:\n",
    "            question_prompt = item['question']\n",
    "            for label, text in zip(item['choices']['label'], item['choices']['text']):\n",
    "                question_prompt += f\"\\n{label}. {text}\"\n",
    "            prompts.append({\n",
    "                'question_prompt': question_prompt,\n",
    "                'answer': item['answerKey']\n",
    "            })\n",
    "        prompts_by_lang[lang] = {'W1': prompts}\n",
    "    elif mode == 'v2_filtered':\n",
    "        prompts = []\n",
    "        for item in data_by_lang[lang]:\n",
    "            question_prompt = item['question']\n",
    "            for label, text in zip(item['choices']['label'], item['choices']['text']):\n",
    "                question_prompt += f\"\\n{label}. {text}\"\n",
    "            prompts.append({\n",
    "                'question_prompt': question_prompt,\n",
    "                'answer': item['answer_majority']\n",
    "            })\n",
    "        prompts_by_lang[lang] = {'W1': prompts}\n",
    "    elif mode == 'v2_raw':\n",
    "        prompts_by_id = {}\n",
    "        for ref_id in tqdm(workers_ids, desc='Processing question prompt'):\n",
    "            prompts = []\n",
    "            for item in data_by_lang[lang][ref_id]:\n",
    "                question_prompt = item['question']\n",
    "                for label, text in zip(item['choices']['label'], item['choices']['text']):\n",
    "                    question_prompt += f\"\\n{label}. {text}\"\n",
    "                prompts.append({\n",
    "                    'question_prompt': question_prompt,\n",
    "                    'answer': item['answer_creator']\n",
    "                })\n",
    "            prompts_by_id[ref_id] = prompts\n",
    "\n",
    "        prompts_by_lang[lang] = prompts_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_prompt': 'Naon nami kaemaman anu didamel tina tipung ketan sareng gula kawung anu diaduk dugika kentel?\\nA. Dodol\\nB. Awug\\nC. Comro\\nD. Misro\\nE. Gegetuk',\n",
       " 'answer': 'A'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_by_lang['sun']['W1'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ChatGPT Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response history found!\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.organization = os.environ['OPENAI_UILAB_KEY']\n",
    "model_name = \"gpt-4-1106-preview\"\n",
    "resp_history_filename = f\"{model_name}_history_231121.csv\"\n",
    "resp_history_path = Path(resp_history_filename)\n",
    "if resp_history_path.is_file():\n",
    "    print(\"Response history found!\")\n",
    "    resp_history_df = pd.read_csv(resp_history_filename)\n",
    "    response_history = dict(zip(resp_history_df.prompt, resp_history_df.response))\n",
    "else:\n",
    "    print(\"Response history not found. Initializing new one...\")\n",
    "    response_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_chat_completion(input_prompt, model_name, resp_num=1, temp=0.1):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': input_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=temp,\n",
    "        n=resp_num\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_prompt(question_prompt):\n",
    "    end_prompt = \"Give only one answer that most likely to be the correct answer with a prefix that says \\\"Answer:\\\" follows by the option letter. For example:\\nAnswer: Z\"\n",
    "    return f\"{question_prompt}\\n\\n{end_prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_answer(input_prompt, model_name, resp_num=1):\n",
    "    if input_prompt in response_history:\n",
    "        return response_history[input_prompt]\n",
    "    \n",
    "    resp = get_openai_chat_completion(input_prompt, model_name, resp_num)\n",
    "    answer = resp.choices[0].message.content.strip().upper()\n",
    "    answer_cleaned = answer.replace('ANSWER: ', '')\n",
    "    if '. ' in answer_cleaned:\n",
    "        answer_cleaned = answer_cleaned.split('. ')[0]\n",
    "\n",
    "    if len(answer_cleaned) > 1:\n",
    "        print('Answer len > 1, retry...')\n",
    "        print('Answer before:', answer_cleaned)\n",
    "        resp = get_openai_chat_completion(input_prompt, model_name, resp_num)\n",
    "        answer = resp.choices[0].message.content.strip().upper()\n",
    "        answer_cleaned = answer.replace('ANSWER: ', '')\n",
    "        if '. ' in answer_cleaned:\n",
    "            answer_cleaned = answer_cleaned.split('. ')[0]\n",
    "        print('Answer after:', answer_cleaned)\n",
    "\n",
    "    response_history[input_prompt] = answer_cleaned\n",
    "    resp_history_df = pd.DataFrame({'prompt': response_history.keys(), 'response': response_history.values()})\n",
    "    resp_history_df.to_csv(resp_history_filename, index=False)\n",
    "\n",
    "    return answer_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 1498/1498 [00:00<00:00, 661863.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: sun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 1499/1499 [00:00<00:00, 404533.63it/s]\n"
     ]
    }
   ],
   "source": [
    "answers_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    answers_by_id = {}\n",
    "    prompts_by_id = prompts_by_lang[lang]\n",
    "    print('Language:', lang)\n",
    "    for ref_id in workers_ids:\n",
    "        answers = []\n",
    "        for prompt_item in tqdm(prompts_by_id[ref_id], desc=f\"Processing {ref_id}\"):\n",
    "            input_prompt = get_input_prompt(prompt_item['question_prompt'])\n",
    "            model_pred = get_openai_answer(input_prompt, model_name, resp_num=1)\n",
    "            answers.append(model_pred)\n",
    "        answers_by_id[ref_id] = answers\n",
    "    answers_by_lang[lang] = answers_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_num_by_lang, acc_by_lang = {}, {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    conflict_num_by_id, acc_by_id = {}, {}\n",
    "    for ref_id in workers_ids:\n",
    "        conflict_num = 0\n",
    "        for pred, gold in zip(answers_by_lang[lang][ref_id], prompts_by_lang[lang][ref_id]):\n",
    "            if pred != gold['answer']:\n",
    "                conflict_num += 1\n",
    "        conflict_num_by_id[ref_id] = conflict_num\n",
    "        acc_by_id[ref_id] = (len(answers_by_lang[lang][ref_id]) - conflict_num) / len(answers_by_lang[lang][ref_id]) * 100\n",
    "    conflict_num_by_lang[lang] = conflict_num_by_id\n",
    "    acc_by_lang[lang] = acc_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4-1106-preview'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': {'W1': 104}, 'sun': {'W1': 233}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_num_by_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ind': {'W1': 93.05740987983978}, 'sun': {'W1': 84.45630420280187}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_by_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze anno conflict num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in ['ind', 'sun']:\n",
    "    # Get gold answer\n",
    "    gold_ans = {}\n",
    "    for ref_id in tqdm(workers_ids):\n",
    "        sh_task1 = client.open_by_key(id_to_key_task1[lang][ref_id])\n",
    "        wks_task1 = sh_task1.worksheet('title', 'Data')\n",
    "        gold_col_num  = 6 if lang == 'ind' else 7\n",
    "        gold_ans[ref_id] = wks_task1.get_col(gold_col_num)[1:]\n",
    "\n",
    "    conflict_data = {}\n",
    "    for pred_id in tqdm(workers_ids):\n",
    "        all_conflict_counts = []\n",
    "        sh_pred = client.open_by_key(id_to_key_task2[lang][pred_id])\n",
    "        for ref_id in workers_ids:\n",
    "            if pred_id == ref_id:\n",
    "                all_conflict_counts.append(0)\n",
    "            else:\n",
    "                wks_pred = sh_pred.worksheet('title', ref_id)\n",
    "\n",
    "                # Get answers\n",
    "                ans_col_num  = 6 if lang == 'ind' else 7\n",
    "                pred_ans = wks_pred.get_col(ans_col_num)[1:]\n",
    "                \n",
    "                # Get conflict status\n",
    "                stat, stat_buffer = [], []\n",
    "                for pred, gold in zip(pred_ans, gold_ans[ref_id]):\n",
    "\n",
    "                    stat_buffer.append('OK' if pred == gold else 'CONFLICT')\n",
    "                    if len(stat_buffer) == 5:\n",
    "                        stat.append('CONFLICT' if 'CONFLICT' in stat_buffer else 'OK')\n",
    "                        stat_buffer = []\n",
    "\n",
    "                ok_count, conflict_count = stat.count('OK'), stat.count('CONFLICT')\n",
    "                if ok_count + conflict_count != 250:\n",
    "                    print(pred_id, ref_id, ok_count, conflict_count)\n",
    "                assert ok_count + conflict_count == 250\n",
    "                all_conflict_counts.append(conflict_count)\n",
    "        conflict_data[pred_id] = all_conflict_counts\n",
    "\n",
    "    conflict_df = pd.DataFrame.from_dict(conflict_data, orient='index', columns=workers_ids)\n",
    "    print('Conflict data for', lang)\n",
    "    print(conflict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
