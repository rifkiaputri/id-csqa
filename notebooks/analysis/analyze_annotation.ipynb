{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pygsheets\n",
    "import pandas as pd\n",
    "import openai\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pygsheets.authorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers_ids = ['W1', 'W2', 'W3', 'W4', 'W5', 'W6']\n",
    "id_to_key_task1 = {\n",
    "    'ind': {\n",
    "        'W1': '14dAiIsBLxBUHzXgFDznMjSXCJmFY6qnIWOADqITWx9E',\n",
    "        'W2': '1jHWRjwkahxpA5T_BWBRaMQ4q9kyg1l0gGz42pC6-dxI',\n",
    "        'W3': '1C-Yyc17WFWScC5eu5WttQc8P8vCFuLvh8MqlBKiwF8c',\n",
    "        'W4': '1J0xqeC05H1RVPSERi8fCXWUTGJ4iH3SI0w59BoFh_KU',\n",
    "        'W5': '1T9jbfP1iapNLS94QZMiYw5K6LrZoP01Qf1jvTWpvdkU',\n",
    "        'W6': '1G0chmXUmWC-lrZLg9ToQTGCdQmnbP0DA204bIKJn9yc',\n",
    "    },\n",
    "    'sun': {\n",
    "        'W1': '1R-bT3RMu41cx-fnac3mNdb3OT_kb6vof1eMdCbU8_jM',\n",
    "        'W2': '1ugtKZhO4jLtxW_yEwrrPXZtry2pLaP-6QgiIHKldl5E',\n",
    "        'W3': '1OzP1XwzU3c-rNXyqxU3JKrrXHeXzSu3D6FIcfym4fHE',\n",
    "        'W4': '1dNwW9dL4YPBEypUHQ6_-Dse8XL851W0WUiCBb28hRBQ',   \n",
    "        'W5': '16wXGP08nESdLg4am4wfngeMNbK81IJAo3p0udg_iVlU',\n",
    "        'W6': '1ZQEBOPGAlc6f2IUwavEKpPHY7dQxV4lN5iSQm1WHnX4',\n",
    "    }\n",
    "}\n",
    "id_to_key_task2 = {\n",
    "    'ind': {\n",
    "        'W1': '1Wa33qUjeB0pq1QI87jUqHTXlQ88ADCxAFp77vFAhSVU',\n",
    "        'W2': '1FbYeTu3ZK4vBLoPVpJqCFB8Rj6yzazYRpxRtmPXXf-k',\n",
    "        'W3': '1UysOeI1QnU8sNXqwQ7FGnULvKCjt8Tm6eoFEdYeQ0xY',\n",
    "        'W4': '1lKIAWvs9D8JoyNrZJzB6pU4KVtfWstH3tOEfM9dZMDc',\n",
    "        'W5': '1nQsQPAoxeRr9QzybjrkpTn5-IuBBCByMNN8txkUVV4w',\n",
    "        'W6': '1SCV9OBxvHwxQ31t6GFirO6et-raMbMpJdfLjn1_HsgU',\n",
    "    },\n",
    "    'sun': {\n",
    "        'W1': '1-FLTsgge53Wgb3HmIlM-oCOWow4_kLEJ0bey8MaMxVI',\n",
    "        'W2': '1-WLiRHFXlD5BawHdBkI2kLSlLttBXU4ufnTwLB8pufM',\n",
    "        'W3': '1EVv6ktg-6ZC5e9UBFvPIVrZI0T2WAbx3OHau_T-OgSE',\n",
    "        'W4': '1XyXhn_R3VuNcsmHCmCEwojFM1hUPGhQe6FDrfo3ALds',\n",
    "        'W5': '1YsreB2g0AeDbiFOIu2JOUmbAkwugBRaaf8SMUA2mrg0',\n",
    "        'W6': '1oU4K52UaKJT3EEvDdOs8o4tD97Wxl4SKSFQK193w2bQ',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data (with commonsense QA format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ind: 100%|██████████| 6/6 [00:16<00:00,  2.80s/it]\n",
      "Processing sun: 100%|██████████| 6/6 [02:01<00:00, 20.30s/it]\n"
     ]
    }
   ],
   "source": [
    "answers_letters = ['A', 'B', 'C', 'D', 'E']\n",
    "cat_id_to_en = {\n",
    "    'Kuliner': 'culinary',\n",
    "    'Tempat': 'place',\n",
    "    'Budaya': 'culture',\n",
    "    'Sejarah': 'history',\n",
    "    'Aktivitas': 'activity',\n",
    "}\n",
    "data_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    data_by_id = {}\n",
    "    for ref_id in tqdm(workers_ids, desc=f'Processing {lang}'):\n",
    "        sh_task1 = client.open_by_key(id_to_key_task1[lang][ref_id])\n",
    "        wks_task1 = sh_task1.worksheet('title', 'Data')\n",
    "\n",
    "        categories = [c for c in wks_task1.get_col(2)[1:] if c != '']\n",
    "        question_concepts = [c for c in wks_task1.get_col(3)[1:] if c != '']\n",
    "        question_concepts_trans = [c for c in wks_task1.get_col(4)[1:] if c != ''] if lang == \"sun\" else []\n",
    "        \n",
    "        question_col_num = 4 if lang == 'ind' else 5\n",
    "        questions = [q for q in wks_task1.get_col(question_col_num)[1:] if q != '']\n",
    "        \n",
    "        options_col_num = 5 if lang == 'ind' else 6\n",
    "        options = wks_task1.get_col(options_col_num)[1:]\n",
    "        options_group, options_buffer = [], []\n",
    "        for option in options:\n",
    "            options_buffer.append(option)\n",
    "            if len(options_buffer) == 5:\n",
    "                options_group.append(options_buffer)\n",
    "                options_buffer = []\n",
    "        \n",
    "        gold_col_num  = 6 if lang == 'ind' else 7\n",
    "        gold = wks_task1.get_col(gold_col_num)[1:]\n",
    "        gold_group, gold_buffer = [], []\n",
    "        for ans in gold:\n",
    "            gold_buffer.append(ans)\n",
    "            if len(gold_buffer) == 5:\n",
    "                gold_group.append(gold_buffer)\n",
    "                gold_buffer = []\n",
    "        \n",
    "        data = []\n",
    "        for i in range(len(questions)):\n",
    "            answer_texts = [o[3:] for o in options_group[i]]\n",
    "            answer = answers_letters[gold_group[i].index('TRUE')]\n",
    "            data.append({\n",
    "                'category': cat_id_to_en[categories[i]],\n",
    "                'question_concepts': question_concepts[i] if lang == 'ind' else question_concepts_trans[i],\n",
    "                'question': questions[i],\n",
    "                'choices': {\n",
    "                    'label': answers_letters,\n",
    "                    'text': answer_texts\n",
    "                },\n",
    "                'answer_creator': answer,\n",
    "                'answers': {},\n",
    "                'answers_uncertainty': {},\n",
    "                'question_ambiguity': {},\n",
    "                'option_ambiguity': {},\n",
    "                'reason': {}\n",
    "            })\n",
    "\n",
    "        data_by_id[ref_id] = data\n",
    "    \n",
    "    data_by_lang[lang] = data_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'adab makan',\n",
       " 'question': 'Apakah adab makan utama masyarakat Indonesia?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Tidak berbicara saat makan',\n",
       "   'Menghabiskan makanan',\n",
       "   'Makan menggunakan tangan kanan',\n",
       "   'Makan sambil duduk',\n",
       "   'Tidak mengecap saat makan']},\n",
       " 'answer_creator': 'C',\n",
       " 'answers': {},\n",
       " 'answers_uncertainty': {},\n",
       " 'question_ambiguity': {},\n",
       " 'option_ambiguity': {},\n",
       " 'reason': {}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lang['ind']['W1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'adab dahar',\n",
       " 'question': 'Dihandap ieu anu termasuk kana adab dahar anu umum di daerah Sunda nyaeta?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Nganggo panangan kenca',\n",
       "   'Nyandak kaemaman anu tebih',\n",
       "   'Dahar bari nyarios',\n",
       "   'Nganggo panangan katuhu',\n",
       "   'Dahar bari diuk']},\n",
       " 'answer_creator': 'D',\n",
       " 'answers': {},\n",
       " 'answers_uncertainty': {},\n",
       " 'question_ambiguity': {},\n",
       " 'option_ambiguity': {},\n",
       " 'reason': {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lang['sun']['W1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 6/6 [00:09<00:00,  1.61s/it]\n",
      "Processing W2: 100%|██████████| 6/6 [02:00<00:00, 20.10s/it]\n",
      "Processing W3: 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "Processing W4: 100%|██████████| 6/6 [00:20<00:00,  3.36s/it]\n",
      "Processing W5: 100%|██████████| 6/6 [00:10<00:00,  1.70s/it]\n",
      "Processing W6: 100%|██████████| 6/6 [00:10<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing W1: 100%|██████████| 6/6 [01:59<00:00, 19.88s/it]\n",
      "Processing W2: 100%|██████████| 6/6 [00:09<00:00,  1.61s/it]\n",
      "Processing W3: 100%|██████████| 6/6 [00:16<00:00,  2.82s/it]\n",
      "Processing W4: 100%|██████████| 6/6 [00:09<00:00,  1.54s/it]\n",
      "Processing W5: 100%|██████████| 6/6 [00:14<00:00,  2.47s/it]\n",
      "Processing W6: 100%|██████████| 6/6 [01:56<00:00, 19.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for lang in ['ind', 'sun']:\n",
    "    print(f'Processing {lang}')\n",
    "    for ref_id in workers_ids:\n",
    "        sh_task2 = client.open_by_key(id_to_key_task2[lang][ref_id])\n",
    "        for pred_id in tqdm(workers_ids, desc=f'Processing {ref_id}'):\n",
    "            if pred_id == ref_id:\n",
    "                continue\n",
    "            wks_task2 = sh_task2.worksheet('title', pred_id)\n",
    "\n",
    "            q_ambiguity_col_num = 8 if lang == 'ind' else 9\n",
    "            q_ambiguity = [q for q in wks_task2.get_col(q_ambiguity_col_num)[1:] if q != '']\n",
    "\n",
    "            uncertainty_col_num = 10 if lang == 'ind' else 11\n",
    "            uncertainty = [q for q in wks_task2.get_col(uncertainty_col_num)[1:] if q != '']\n",
    "\n",
    "            reason_col_num = 11 if lang == 'ind' else 12\n",
    "            reasons = wks_task2.get_col(reason_col_num)[1:]\n",
    "            reason_single, reason_buffer = [], []\n",
    "            for reason in reasons:\n",
    "                reason_buffer.append(reason)\n",
    "                if len(reason_buffer) == 5:\n",
    "                    reason_single.append(reason_buffer[0])\n",
    "                    reason_buffer = []\n",
    "\n",
    "            answer_col_num = 6 if lang == 'ind' else 7\n",
    "            answers = wks_task2.get_col(answer_col_num)[1:]\n",
    "            answers_single, answers_buffer = [], []\n",
    "            for answer in answers:\n",
    "                answers_buffer.append(answer)\n",
    "                if len(answers_buffer) == 5:\n",
    "                    answers_single.append(answers_letters[answers_buffer.index('TRUE')])\n",
    "                    answers_buffer = []\n",
    "\n",
    "            options_col_num = 9 if lang == 'ind' else 10\n",
    "            options = wks_task2.get_col(options_col_num)[1:]\n",
    "            options_group, options_buffer = [], []\n",
    "            for option in options:\n",
    "                options_buffer.append(option)\n",
    "                if len(options_buffer) == 5:\n",
    "                    options_group.append(options_buffer)\n",
    "                    options_buffer = []\n",
    "            \n",
    "            for i in range(len(q_ambiguity)):\n",
    "                data_by_lang[lang][pred_id][i]['answers'][ref_id] = answers_single[i]\n",
    "                data_by_lang[lang][pred_id][i]['answers_uncertainty'][ref_id] = uncertainty[i]\n",
    "                data_by_lang[lang][pred_id][i]['question_ambiguity'][ref_id] = q_ambiguity[i]\n",
    "                data_by_lang[lang][pred_id][i]['option_ambiguity'][ref_id] = options_group[i]\n",
    "                data_by_lang[lang][pred_id][i]['reason'][ref_id] = reason_single[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'aduk',\n",
       " 'question': 'Apa yang biasanya digunakan untuk mengaduk kopi?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Sedotan', 'Bungkus kopi', 'Garpu', 'Sumpit', 'Sendok']},\n",
       " 'answer_creator': 'C',\n",
       " 'answers': {'W2': 'E', 'W3': 'E', 'W4': 'E', 'W5': 'A', 'W6': 'E'},\n",
       " 'answers_uncertainty': {'W2': 'certain',\n",
       "  'W3': 'certain',\n",
       "  'W4': 'certain',\n",
       "  'W5': 'certain',\n",
       "  'W6': 'certain'},\n",
       " 'question_ambiguity': {'W2': 'clear',\n",
       "  'W3': 'clear',\n",
       "  'W4': 'clear',\n",
       "  'W5': 'clear',\n",
       "  'W6': 'clear'},\n",
       " 'option_ambiguity': {'W2': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W3': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W4': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W5': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W6': ['clear', 'clear', 'clear', 'clear', 'clear']},\n",
       " 'reason': {'W2': '', 'W3': '', 'W4': '', 'W5': '', 'W6': ''}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lang['ind']['W1'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'adab dahar',\n",
       " 'question': 'Dihandap ieu anu termasuk kana adab dahar anu umum di daerah Sunda nyaeta?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Nganggo panangan kenca',\n",
       "   'Nyandak kaemaman anu tebih',\n",
       "   'Dahar bari nyarios',\n",
       "   'Nganggo panangan katuhu',\n",
       "   'Dahar bari diuk']},\n",
       " 'answer_creator': 'D',\n",
       " 'answers': {'W2': 'D', 'W3': 'D', 'W4': 'D', 'W5': 'D', 'W6': 'D'},\n",
       " 'answers_uncertainty': {'W2': 'certain',\n",
       "  'W3': 'certain',\n",
       "  'W4': 'certain',\n",
       "  'W5': 'certain',\n",
       "  'W6': 'certain'},\n",
       " 'question_ambiguity': {'W2': 'clear',\n",
       "  'W3': 'clear',\n",
       "  'W4': 'clear',\n",
       "  'W5': 'clear',\n",
       "  'W6': 'clear'},\n",
       " 'option_ambiguity': {'W2': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W3': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W4': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W5': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W6': ['clear', 'clear', 'clear', 'clear', 'clear']},\n",
       " 'reason': {'W2': '', 'W3': '', 'W4': '', 'W5': '', 'W6': ''}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lang['sun']['W1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the dataset\n",
    "for lang in ['ind', 'sun']:\n",
    "    with open(f'../dataset/human/raw_{lang}.json', 'w', encoding='utf-8') as fp:\n",
    "        json.dump(data_by_lang[lang], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing question prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing question prompt: 100%|██████████| 6/6 [00:00<00:00, 986.47it/s]\n",
      "Processing question prompt: 100%|██████████| 6/6 [00:00<00:00, 782.28it/s]\n"
     ]
    }
   ],
   "source": [
    "answers_letters = ['A', 'B', 'C', 'D', 'E']\n",
    "prompts_by_lang, data_by_lang = {}, {}\n",
    "mode = 'raw'\n",
    "if mode == 'raw':\n",
    "    for lang in ['ind', 'sun']:\n",
    "        prompts_by_id = {}\n",
    "        with open(f'../dataset/human/raw_{lang}.json', encoding='utf-8') as fp:\n",
    "            data_by_lang[lang] = json.load(fp)\n",
    "        for ref_id in tqdm(workers_ids, desc='Processing question prompt'):\n",
    "            prompts = []\n",
    "            for item in data_by_lang[lang][ref_id]:\n",
    "                question_prompt = item['question']\n",
    "                for label, text in zip(item['choices']['label'], item['choices']['text']):\n",
    "                    question_prompt += f\"\\n{label}. {text}\"\n",
    "                prompts.append({\n",
    "                    'question_prompt': question_prompt,\n",
    "                    'answer': item['answer_creator']\n",
    "                })\n",
    "\n",
    "            prompts_by_id[ref_id] = prompts\n",
    "        \n",
    "        prompts_by_lang[lang] = prompts_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'culinary',\n",
       " 'question_concepts': 'adab makan',\n",
       " 'question': 'Apakah adab makan utama masyarakat Indonesia?',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['Tidak berbicara saat makan',\n",
       "   'Menghabiskan makanan',\n",
       "   'Makan menggunakan tangan kanan',\n",
       "   'Makan sambil duduk',\n",
       "   'Tidak mengecap saat makan']},\n",
       " 'answer_creator': 'C',\n",
       " 'answers': {'W2': 'C', 'W3': 'C', 'W4': 'C', 'W5': 'C', 'W6': 'C'},\n",
       " 'answers_uncertainty': {'W2': 'certain',\n",
       "  'W3': 'certain',\n",
       "  'W4': 'uncertain',\n",
       "  'W5': 'uncertain',\n",
       "  'W6': 'certain'},\n",
       " 'question_ambiguity': {'W2': 'clear',\n",
       "  'W3': 'clear',\n",
       "  'W4': 'clear',\n",
       "  'W5': 'clear',\n",
       "  'W6': 'clear'},\n",
       " 'option_ambiguity': {'W2': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W3': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W4': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W5': ['clear', 'clear', 'clear', 'clear', 'clear'],\n",
       "  'W6': ['clear', 'clear', 'clear', 'clear', 'clear']},\n",
       " 'reason': {'W2': '',\n",
       "  'W3': '',\n",
       "  'W4': '[Uncertain] Pilihannya sudah jelas, namun hampir setara',\n",
       "  'W5': '[uncertain] tidak yakin mengisi jawaban karena semua options terasa benar',\n",
       "  'W6': ''}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lang['ind']['W1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_prompt': 'Apakah adab makan utama masyarakat Indonesia?\\nA. Tidak berbicara saat makan\\nB. Menghabiskan makanan\\nC. Makan menggunakan tangan kanan\\nD. Makan sambil duduk\\nE. Tidak mengecap saat makan',\n",
       " 'answer': 'C'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_by_lang['ind']['W1'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ChatGPT Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.organization = os.environ['OPENAI_UILAB_KEY']\n",
    "model_name = \"gpt-4-1106-preview\"\n",
    "resp_history_filename = f\"{model_name}_history_231107.csv\"\n",
    "resp_history_path = Path(resp_history_filename)\n",
    "if resp_history_path.is_file():\n",
    "    print(\"Response history found!\")\n",
    "    resp_history_df = pd.read_csv(resp_history_filename)\n",
    "    response_history = dict(zip(resp_history_df.prompt, resp_history_df.response))\n",
    "else:\n",
    "    print(\"Response history not found. Initializing new one...\")\n",
    "    response_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_chat_completion(input_prompt, model_name, resp_num=1, temp=0.1):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': input_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=temp,\n",
    "        n=resp_num\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_prompt(question_prompt):\n",
    "    end_prompt = \"Give only one answer that most likely to be the correct answer with a prefix that says \\\"Answer:\\\" follows by the option letter. For example:\\nAnswer: Z\"\n",
    "    return f\"{question_prompt}\\n\\n{end_prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_answer(input_prompt, model_name, resp_num=1):\n",
    "    if input_prompt in response_history:\n",
    "        return response_history[input_prompt]\n",
    "    \n",
    "    resp = get_openai_chat_completion(input_prompt, model_name, resp_num)\n",
    "    answer = resp.choices[0].message.content.strip().upper()\n",
    "    answer_cleaned = answer.replace('ANSWER: ', '')\n",
    "    if '. ' in answer_cleaned:\n",
    "        answer_cleaned = answer_cleaned.split('. ')[0]\n",
    "\n",
    "    if len(answer_cleaned) > 1:\n",
    "        print('Answer len > 1, retry...')\n",
    "        print('Answer before:', answer_cleaned)\n",
    "        resp = get_openai_chat_completion(input_prompt, model_name, resp_num)\n",
    "        answer = resp.choices[0].message.content.strip().upper()\n",
    "        answer_cleaned = answer.replace('ANSWER: ', '')\n",
    "        if '. ' in answer_cleaned:\n",
    "            answer_cleaned = answer_cleaned.split('. ')[0]\n",
    "        print('Answer after:', answer_cleaned)\n",
    "\n",
    "    response_history[input_prompt] = answer_cleaned\n",
    "    resp_history_df = pd.DataFrame({'prompt': response_history.keys(), 'response': response_history.values()})\n",
    "    resp_history_df.to_csv(resp_history_filename, index=False)\n",
    "\n",
    "    return answer_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    answers_by_id = {}\n",
    "    prompts_by_id = prompts_by_lang[lang]\n",
    "    print('Language:', lang)\n",
    "    for ref_id in workers_ids:\n",
    "        answers = []\n",
    "        for prompt_item in tqdm(prompts_by_id[ref_id], desc=f\"Processing {ref_id}\"):\n",
    "            input_prompt = get_input_prompt(prompt_item['question_prompt'])\n",
    "            model_pred = get_openai_answer(input_prompt, model_name, resp_num=1)\n",
    "            answers.append(model_pred)\n",
    "        answers_by_id[ref_id] = answers\n",
    "    answers_by_lang[lang] = answers_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_num_by_lang = {}\n",
    "for lang in ['ind', 'sun']:\n",
    "    conflict_num_by_id = {}\n",
    "    for ref_id in workers_ids:\n",
    "        conflict_num = 0\n",
    "        for pred, gold in zip(answers_by_lang[lang][ref_id], prompts_by_lang[lang][ref_id]):\n",
    "            if pred != gold['answer']:\n",
    "                conflict_num += 1\n",
    "        conflict_num_by_id[ref_id] = conflict_num\n",
    "    conflict_num_by_lang[lang] = conflict_num_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_num_by_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze anno conflict num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in ['ind', 'sun']:\n",
    "    # Get gold answer\n",
    "    gold_ans = {}\n",
    "    for ref_id in tqdm(workers_ids):\n",
    "        sh_task1 = client.open_by_key(id_to_key_task1[lang][ref_id])\n",
    "        wks_task1 = sh_task1.worksheet('title', 'Data')\n",
    "        gold_col_num  = 6 if lang == 'ind' else 7\n",
    "        gold_ans[ref_id] = wks_task1.get_col(gold_col_num)[1:]\n",
    "\n",
    "    conflict_data = {}\n",
    "    for pred_id in tqdm(workers_ids):\n",
    "        all_conflict_counts = []\n",
    "        sh_pred = client.open_by_key(id_to_key_task2[lang][pred_id])\n",
    "        for ref_id in workers_ids:\n",
    "            if pred_id == ref_id:\n",
    "                all_conflict_counts.append(0)\n",
    "            else:\n",
    "                wks_pred = sh_pred.worksheet('title', ref_id)\n",
    "\n",
    "                # Get answers\n",
    "                ans_col_num  = 6 if lang == 'ind' else 7\n",
    "                pred_ans = wks_pred.get_col(ans_col_num)[1:]\n",
    "                \n",
    "                # Get conflict status\n",
    "                stat, stat_buffer = [], []\n",
    "                for pred, gold in zip(pred_ans, gold_ans[ref_id]):\n",
    "\n",
    "                    stat_buffer.append('OK' if pred == gold else 'CONFLICT')\n",
    "                    if len(stat_buffer) == 5:\n",
    "                        stat.append('CONFLICT' if 'CONFLICT' in stat_buffer else 'OK')\n",
    "                        stat_buffer = []\n",
    "\n",
    "                ok_count, conflict_count = stat.count('OK'), stat.count('CONFLICT')\n",
    "                if ok_count + conflict_count != 250:\n",
    "                    print(pred_id, ref_id, ok_count, conflict_count)\n",
    "                assert ok_count + conflict_count == 250\n",
    "                all_conflict_counts.append(conflict_count)\n",
    "        conflict_data[pred_id] = all_conflict_counts\n",
    "\n",
    "    conflict_df = pd.DataFrame.from_dict(conflict_data, orient='index', columns=workers_ids)\n",
    "    print('Conflict data for', lang)\n",
    "    print(conflict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
