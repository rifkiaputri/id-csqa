{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\rn\\KAIST\\College\\Project\\Indo Commonsense QA\\id-csqa\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from google.cloud import translate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path, bool_params):\n",
    "    # Initialize an empty list to store the data\n",
    "    data_list = []\n",
    "\n",
    "    # Open the CSV file for reading\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        # Create a CSV reader object\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            # Append the row (as a dictionary) to the data_list\n",
    "            row[\"choices\"] = ast.literal_eval(row[\"choices\"])\n",
    "\n",
    "            for param in bool_params:\n",
    "                if row[param].lower() == \"true\":\n",
    "                    row[param] = True\n",
    "                elif row[param].lower() == \"false\":\n",
    "                    row[param] = False\n",
    "                else:\n",
    "                    raise TypeError(f\"{param} data cannot be recognized\")\n",
    "\n",
    "            data_list.append(row)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "def load_all_rephrase_data(split, dir_path, file_name):\n",
    "    data = {}\n",
    "    \n",
    "    for s in split:\n",
    "        file_path = f\"{dir_path}/{s}{file_name}\"\n",
    "        data[s] = load_csv_data(file_path, [])\n",
    "        # data[s] = load_csv_data(file_path, [\"concept\", \"name\", \"option\"])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_data(samples, file_path):\n",
    "    # Get the keys from the first dictionary\n",
    "    header = samples[0].keys()\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    with open(file_path, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the data\n",
    "        for row in samples:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f'CSV file \"{file_path}\" has been created with the data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Translate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_texts(texts, project_id=\"radiant-math-403602\", src_lang=\"en\", tgt_lang=\"id\"):\n",
    "\n",
    "    client = translate.TranslationServiceClient()\n",
    "    location = \"global\"\n",
    "    parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "    response = client.translate_text(\n",
    "        request={\n",
    "            \"parent\": parent,\n",
    "            \"contents\": texts,\n",
    "            \"mime_type\": \"text/plain\",\n",
    "            \"source_language_code\": src_lang,\n",
    "            \"target_language_code\": tgt_lang,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return [t.translated_text for t in response.translations]\n",
    "\n",
    "def translate_data(data, src_lang=\"en\", tgt_lang=\"id\"):\n",
    "    results = []\n",
    "    for item in tqdm(data):\n",
    "        trans_items = [item['question'], item['question_concept']] + item['choices']['text']\n",
    "\n",
    "        try:\n",
    "            trans_texts = translate_texts(trans_items, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "        except Exception:\n",
    "            print('Caught exception, wait for 1 min...')\n",
    "            time.sleep(60)\n",
    "            trans_texts = translate_texts(trans_items, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        results.append({\n",
    "            'id': item['id'],\n",
    "            'question': trans_texts[0],\n",
    "            'question_concept': trans_texts[1],\n",
    "            'choices': {\n",
    "                'label': item['choices']['label'],\n",
    "                'text': trans_texts[2:]\n",
    "            },\n",
    "            'answerKey': item['answerKey']\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [\"validation\", \"test\", \"train\"]\n",
    "# en_data = load_all_rephrase_data(split, \"92123\", \"_rephrased_name_92123.csv\")\n",
    "id_data = load_all_rephrase_data(split, \"translated_data/id\", \".csv\")\n",
    "su_data = load_all_rephrase_data(split, \"translated_data/su\", \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6917399ea434e6c484459f895c72ef90',\n",
       " 'question': 'Jenis sumur naon waÃ© anu tiasa nyababkeun kontrovÃ©rsi?',\n",
       " 'question_concept': 'Sehat',\n",
       " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
       "  'text': ['panasbumi',\n",
       "   'cai taneuh',\n",
       "   'minyak jeung gas',\n",
       "   'tatanÃ©n',\n",
       "   'artesian']},\n",
       " 'answerKey': 'C'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "su_data[\"test\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating data split validation\n",
      "Backtranslation for ID -> EN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [07:35<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/id_en/validation.csv\" has been created with the data.\n",
      "Backtranslation for SU -> EN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [07:24<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/su_en/validation.csv\" has been created with the data.\n",
      "Backtranslation for SU -> ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [07:39<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/su_id/validation.csv\" has been created with the data.\n",
      "Translating data split test\n",
      "Backtranslation for ID -> EN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [06:23<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/id_en/test.csv\" has been created with the data.\n",
      "Backtranslation for SU -> EN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [06:26<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/su_en/test.csv\" has been created with the data.\n",
      "Backtranslation for SU -> ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [06:27<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/su_id/test.csv\" has been created with the data.\n",
      "Translating data split train\n",
      "Backtranslation for ID -> EN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2162/2162 [1:50:34<00:00,  3.07s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/id_en/train.csv\" has been created with the data.\n",
      "Backtranslation for SU -> EN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1958/2162 [50:57<05:13,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught exception, wait for 1 min...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2162/2162 [57:34<00:00,  1.60s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/su_en/train.csv\" has been created with the data.\n",
      "Backtranslation for SU -> ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2162/2162 [57:50<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./backtranslation/su_id/train.csv\" has been created with the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for s in split:\n",
    "    print(f\"Translating data split {s}\")\n",
    "    print(f\"Backtranslation for ID -> EN\")\n",
    "    id_en = translate_data(id_data[s], src_lang=\"id\", tgt_lang=\"en\")\n",
    "    save_data(id_en, f\"./backtranslation/id_en/{s}.csv\")\n",
    "\n",
    "    print(f\"Backtranslation for SU -> EN\")\n",
    "    su_en = translate_data(su_data[s], src_lang=\"su\", tgt_lang=\"en\")\n",
    "    save_data(su_en, f\"./backtranslation/su_en/{s}.csv\")\n",
    "\n",
    "    print(f\"Backtranslation for SU -> ID\")\n",
    "    su_id = translate_data(su_data[s], src_lang=\"su\", tgt_lang=\"id\")\n",
    "    save_data(su_id, f\"./backtranslation/su_id/{s}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idlocal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
