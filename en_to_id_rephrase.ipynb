{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"API_KEY\")\n",
    "org_key = os.environ.get(\"ORG_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV Rephrase Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file\n",
    "split = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for s in split:\n",
    "    csv_file_path = f'{s}_rephrase.csv'\n",
    "\n",
    "    # Initialize an empty list to store the data\n",
    "    data_list = []\n",
    "\n",
    "    # Open the CSV file for reading\n",
    "    with open(csv_file_path, newline='') as csvfile:\n",
    "        # Create a CSV reader object\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            # Append the row (as a dictionary) to the data_list\n",
    "            row[\"choices\"] = ast.literal_eval(row[\"choices\"])\n",
    "\n",
    "            rephrase_params = [\"concept\", \"name\", \"option\"]\n",
    "            for param in rephrase_params:\n",
    "                if row[param] == \"True\":\n",
    "                    row[param] = True\n",
    "                elif row[param] == \"False\":\n",
    "                    row[param] = False\n",
    "                else:\n",
    "                    raise TypeError(f\"{param} data cannot be recognized\")\n",
    "\n",
    "            data_list.append(row)\n",
    "    \n",
    "    all_data[s] = data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate choice text\n",
    "def generate_choices_text(choices):\n",
    "    labels = choices[\"label\"]\n",
    "    texts = choices[\"text\"]\n",
    "\n",
    "    choice_text = \"\"\n",
    "    for idx, label in enumerate(labels):\n",
    "        choice_text += f'{label}. \"{texts[idx]}\"\\n'\n",
    "    \n",
    "    return choice_text\n",
    "\n",
    "# Function to generate answer text\n",
    "def generate_answer_text(choices, answerKey):\n",
    "    idx = choices[\"label\"].index(answerKey)\n",
    "    answer_text = f'{answerKey}. \"{choices[\"text\"][idx]}\"'\n",
    "    \n",
    "    return answer_text\n",
    "\n",
    "# Function to generate prompts based on the conditions\n",
    "def generate_rephrase_name_prompt(row):\n",
    "    return f\"\"\"Change all names in the given phrases to Indonesian names. Change only the names. Keep all remaining phrases and keep it all in english and reply with only your answer.\n",
    "\n",
    "Phrase: {row['question']}\n",
    "Answer:\"\"\"\n",
    "\n",
    "def generate_rephrase_all_prompt(row):\n",
    "    return f\"\"\"Given a commonsense question, a concept, options, and the question answer, change them to become relevant to Indonesia. If an aspect is flagged to be changed, then you need to change it completely. If it's flagged as keep, then keep as it is. Make sure your changes are still in the same domain/topic with the given data, and there is only one clear answer in the options. Reply with only your changed data in a JSON format.\n",
    "\n",
    "Data:\n",
    "###\n",
    "Question: {row['question']} -> Change\n",
    "Concept: {row['question_concept']} -> {'Change' if row['concept'] else 'Keep'}\n",
    "Options: -> {'Change' if row['option'] else 'Keep'}\n",
    "{generate_choices_text(row['choices'])}Question Answer: {generate_answer_text(row['choices'], row['answerKey']) if row['answerKey'] else ''}\n",
    "###\n",
    "\n",
    "Changed data:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rephrase Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_chat_completion(input_prompt, model_name):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': input_prompt \n",
    "            }\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "# Define a function to rephrase the CSV data using OpenAI GPT-3.5-Turbo\n",
    "def rephrase_csv_data(row, model_name, history):\n",
    "    if row[\"name\"] and not row[\"concept\"] and not row[\"option\"]:\n",
    "        input_prompt = generate_rephrase_name_prompt(row)\n",
    "    else:\n",
    "        input_prompt = generate_rephrase_all_prompt(row)\n",
    "\n",
    "    if input_prompt in history.keys():\n",
    "        return history[input_prompt]\n",
    "\n",
    "    try:\n",
    "        completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "    except Exception:\n",
    "        print('Caught exception, wait for 1 min...')\n",
    "        time.sleep(60)\n",
    "        completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "    \n",
    "    response = completion.choices[0].message.content.strip()\n",
    "            \n",
    "    return input_prompt, response\n",
    "\n",
    "def postprocess_result(row, response, split):\n",
    "    if row[\"name\"] and not row[\"concept\"] and not row[\"option\"]:\n",
    "        if \"Answer: \" in response:\n",
    "            rephrased_result = response.split(\"Answer: \")[-1]\n",
    "        else:\n",
    "            rephrased_result = response\n",
    "    else:\n",
    "        rephrased_result = ast.literal_eval(response)\n",
    "        letters = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "        if isinstance(rephrased_result[\"Options\"], list):\n",
    "            if len(rephrased_result[\"Options\"]) == 5:\n",
    "                rephrased_result[\"Options\"] = dict(zip(letters, rephrased_result[\"Options\"]))\n",
    "            else:\n",
    "                raise ValueError(f\"Option output is not right: {rephrased_result['Options']}\")\n",
    "        \n",
    "        if split != \"test\":\n",
    "            rephrased_result[\"Question Answer\"] = rephrased_result[\"Question Answer\"][0]\n",
    "            if rephrased_result[\"Question Answer\"] not in letters:\n",
    "                raise ValueError(f\"Answer key not in options: {rephrased_result['Question Answer']}\")\n",
    "    \n",
    "    return rephrased_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Rephrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key\n",
    "openai.organization = org_key\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data on split: train\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response history saved to train_history_91023.csv\n",
      "CSV file \"train_rephrased.csv\" has been created with the data.\n",
      "Process data on split: validation\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response history saved to validation_history_91023.csv\n",
      "CSV file \"validation_rephrased.csv\" has been created with the data.\n",
      "Process data on split: test\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Anwer key not in options: r",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(all_data[s][:\u001b[39m10\u001b[39m]):\n\u001b[0;32m     15\u001b[0m     rephrased_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 17\u001b[0m     prompt, result \u001b[39m=\u001b[39m rephrase_csv_data(data, model_name, response_history)\n\u001b[0;32m     18\u001b[0m     response_history[prompt] \u001b[39m=\u001b[39m result\n\u001b[0;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m):\n",
      "Cell \u001b[1;32mIn[146], line 49\u001b[0m, in \u001b[0;36mrephrase_csv_data\u001b[1;34m(row, model_name, history)\u001b[0m\n\u001b[0;32m     47\u001b[0m     rephrased_result[\u001b[39m\"\u001b[39m\u001b[39mQuestion Answer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m rephrased_result[\u001b[39m\"\u001b[39m\u001b[39mQuestion Answer\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m rephrased_result[\u001b[39m\"\u001b[39m\u001b[39mQuestion Answer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m letters:\n\u001b[1;32m---> 49\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAnwer key not in options: \u001b[39m\u001b[39m{\u001b[39;00mrephrased_result[\u001b[39m'\u001b[39m\u001b[39mQuestion Answer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m input_prompt, rephrased_result\n",
      "\u001b[1;31mValueError\u001b[0m: Anwer key not in options: r"
     ]
    }
   ],
   "source": [
    "for s in split:\n",
    "    print(f\"Process data on split: {s}\")\n",
    "    \n",
    "    history_path = f\"{s}_history_91023.csv\"\n",
    "    if os.path.exists(history_path):\n",
    "        print(f\"Load response history from file {history_path}\")\n",
    "        resp_history_df = pd.read_csv(history_path, converters={'response': lambda x: ast.literal_eval(x)})\n",
    "        response_history = dict(zip(resp_history_df.prompt, resp_history_df.response))\n",
    "    else:\n",
    "        print(f\"Initialize response history\")\n",
    "        response_history = {}\n",
    "\n",
    "    rephrased_results = []\n",
    "    for data in tqdm(all_data[s][:10]):\n",
    "        rephrased_data = data.copy()\n",
    "        \n",
    "        prompt, response = rephrase_csv_data(data, model_name, response_history)\n",
    "        response_history[prompt] = response\n",
    "        \n",
    "        result = postprocess_result(data, response, s)\n",
    "        if isinstance(result, dict):\n",
    "            rephrased_data[\"question\"] = result[\"Question\"]\n",
    "            rephrased_data[\"question_concept\"] = result[\"Concept\"]\n",
    "            rephrased_data[\"choices\"] = {\n",
    "                \"label\": list(result[\"Options\"].keys()),\n",
    "                \"text\": list(result[\"Options\"].values())\n",
    "            }\n",
    "            if s != \"test\":\n",
    "                rephrased_data[\"answerKey\"] = result[\"Question Answer\"]\n",
    "        elif isinstance(result, str):\n",
    "            rephrased_data[\"question\"] = result\n",
    "        \n",
    "        rephrased_results.append(rephrased_data)\n",
    "    \n",
    "    resp_history_df = pd.DataFrame({'prompt': response_history.keys(), 'response': response_history.values()})\n",
    "    resp_history_df.to_csv(history_path, index=False)\n",
    "\n",
    "    print(f\"Response history saved to {history_path}\")\n",
    "\n",
    "    # Specify the path to the CSV file\n",
    "    rephrased_file_path = f'{s}_rephrased.csv'\n",
    "\n",
    "    # Get the keys from the first dictionary\n",
    "    header = rephrased_results[0].keys()\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    with open(rephrased_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the data\n",
    "        for row in rephrased_results:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f'CSV file \"{rephrased_file_path}\" has been created with the data.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\n",
    "    'Question': 'Where is a Javanese eagle safe?',\n",
    "    'Concept': 'Javanese eagle',\n",
    "    'Options': {'A': 'rainforest',\n",
    "    'B': 'rice fields',\n",
    "    'C': 'in Java',\n",
    "    'D': 'national park',\n",
    "    'E': 'mountain'},\n",
    "    'Question Answer': 'D'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x[\"Options\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['A', 'B', 'C', 'D', 'E'],\n",
       " 'text': ['rainforest', 'rice fields', 'in Java', 'national park', 'mountain']}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_option = {\"label\": list(y.keys()), \"text\": list(y.values())}\n",
    "new_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
