{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import stanza\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needs to be run one time\n",
    "# stanza.download('en', model_dir=os.environ['HF_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_name = 'train'\n",
    "# en_csqa = load_dataset('commonsense_qa', split=split_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Relevancy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('republican')[0].pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_response_history = {}\n",
    "adj_and_adv = [wn.ADJ, wn.ADJ_SAT, wn.ADV]\n",
    "def is_adj_or_adv(concept):\n",
    "    concept = '_'.join(concept.split())\n",
    "    synsets = wn.synsets(concept)\n",
    "    if len(synsets) > 0:\n",
    "        pos_tag = synsets[0].pos()\n",
    "    else:\n",
    "        pos_tag = ''\n",
    "\n",
    "    if pos_tag in adj_and_adv:\n",
    "        is_adj = True\n",
    "    else:\n",
    "        is_adj = False\n",
    "\n",
    "    adj_response_history[concept] = is_adj\n",
    "    \n",
    "    return is_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 17:50:06 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| lemma     | combined |\n",
      "========================\n",
      "\n",
      "2023-07-31 17:50:06 INFO: Using device: 0\n",
      "2023-07-31 17:50:06 INFO: Loading: tokenize\n",
      "2023-07-31 17:50:07 INFO: Loading: lemma\n",
      "2023-07-31 17:50:07 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,lemma', device=0, model_dir=os.environ['HF_HOME'], download_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options_lemma(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(f\"https://api.conceptnet.io/query?node=/c/en/body_part&limit=5000\")\n",
    "obj = res.json()\n",
    "body_parts = set()\n",
    "for edge in obj['edges']:\n",
    "    start_edge = edge['start']['@id'].replace('/c/en/', '')\n",
    "    if '/' not in start_edge:\n",
    "        body_parts.add(start_edge.replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_concepts = [\n",
    "    \"sex\", \"vagina\", \"penis\", \"prostitute\", \"kiss\", \"copulating\", \"procreating\",\n",
    "    \"killing people\", \"committing murder\", \"affair\", \"drug dealer\", \"terrorists\", \"terrorist\",\n",
    "]\n",
    "general_concepts = [\n",
    "    \"human\", \"animal\", \"plant\", \"thing\", \"everyone\", \"people\", \"person\"\n",
    "] + list(body_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset commonsense_qa (/media/kiki/kiki_hdd/cache/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n",
      "100%|██████████| 9741/9741 [02:10<00:00, 74.57it/s] \n",
      "Found cached dataset commonsense_qa (/media/kiki/kiki_hdd/cache/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n",
      "100%|██████████| 1221/1221 [00:16<00:00, 72.99it/s]\n",
      "Found cached dataset commonsense_qa (/media/kiki/kiki_hdd/cache/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n",
      "100%|██████████| 1140/1140 [00:14<00:00, 78.85it/s] \n",
      "Found cached dataset commonsense_qa (/media/kiki/kiki_hdd/cache/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n",
      "100%|██████████| 9741/9741 [02:05<00:00, 77.81it/s] \n",
      "Found cached dataset commonsense_qa (/media/kiki/kiki_hdd/cache/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n",
      "100%|██████████| 1221/1221 [00:15<00:00, 76.41it/s]\n",
      "Found cached dataset commonsense_qa (/media/kiki/kiki_hdd/cache/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n",
      "100%|██████████| 1140/1140 [00:14<00:00, 77.09it/s] \n"
     ]
    }
   ],
   "source": [
    "out_parent_dir = \"../dataset/relevancy_ensemble/\"\n",
    "for lang_name in [\"id\", \"su\"]:\n",
    "    for split_name in [\"train\", \"validation\", \"test\"]:\n",
    "        en_csqa = load_dataset('commonsense_qa', split=split_name)\n",
    "        relevancy_df = pd.read_csv(f\"{out_parent_dir}{split_name}_{lang_name}_relevancy.csv\", index_col=0, converters={'q_concept': lambda x: x[1:-1].replace(\"'\", '').split(', ')})\n",
    "\n",
    "        general_questions, rephrase_questions = [], []\n",
    "        for item in tqdm(en_csqa):\n",
    "            q_id = item['id']\n",
    "\n",
    "            # Check q concept offensiveness\n",
    "            options_str = ' '.join(item['choices']['text']).lower()\n",
    "            is_offensive = any(ex in item['question'].lower() for ex in excluded_concepts) or \\\n",
    "                any(ex in options_str for ex in excluded_concepts)\n",
    "            if is_offensive:\n",
    "                continue\n",
    "\n",
    "            # Check options ambiguity\n",
    "            options_lemma = [get_options_lemma(option) for option in item['choices']['text']]\n",
    "            is_options_ambiguous = len(set(options_lemma)) != len(options_lemma)\n",
    "            if is_options_ambiguous:\n",
    "                continue\n",
    "\n",
    "            # Check name relevancy\n",
    "            is_name_irrelevant = relevancy_df.loc[q_id, 'names'] != \"[]\"\n",
    "\n",
    "            # Check options relevancy\n",
    "            options = [\n",
    "                relevancy_df.loc[q_id, 'option_a'], relevancy_df.loc[q_id, 'option_b'],\n",
    "                relevancy_df.loc[q_id, 'option_c'], relevancy_df.loc[q_id, 'option_d'],\n",
    "                relevancy_df.loc[q_id, 'option_e']\n",
    "            ]\n",
    "            is_option_irrelevant = 'no' in options\n",
    "\n",
    "            # Check q concept relevancy\n",
    "            yes_count = relevancy_df.loc[q_id, 'q_concept'].count('yes')\n",
    "            no_count = relevancy_df.loc[q_id, 'q_concept'].count('no')\n",
    "\n",
    "            # Check concept generality\n",
    "            is_general_concepts = any(c in item['question_concept'] for c in general_concepts) or is_adj_or_adv(item['question_concept'])\n",
    "            \n",
    "            if not is_name_irrelevant and not is_option_irrelevant and (is_general_concepts or yes_count >= 4):\n",
    "                general_questions.append(item)\n",
    "            else:\n",
    "                if (not is_general_concepts and no_count >= 4) or is_name_irrelevant or is_option_irrelevant:\n",
    "                    item['concept'] = no_count >= 4\n",
    "                    item['name'] = is_name_irrelevant\n",
    "                    item['option'] = is_option_irrelevant\n",
    "                    rephrase_questions.append(item)\n",
    "\n",
    "        q_df_general = pd.DataFrame(general_questions)\n",
    "        q_df_rephrase = pd.DataFrame(rephrase_questions)\n",
    "\n",
    "        q_df_general.to_csv(f\"{out_parent_dir}data_result/{split_name}_general_{lang_name}.csv\", index=False)\n",
    "        q_df_rephrase.to_csv(f\"{out_parent_dir}data_result/{split_name}_rephrase_{lang_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index, lang_index = [], []\n",
    "for lang in ['id', 'su']:\n",
    "    for split in ['train', 'validation', 'test']:\n",
    "        lang_index.append(lang)\n",
    "        split_index.append(split)\n",
    "data_stat = pd.DataFrame(index=[np.array(lang_index), np.array(split_index)], columns=['general', 'rephrase', 'irr_concept', 'irr_location', 'irr_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 193.49it/s]\n"
     ]
    }
   ],
   "source": [
    "out_parent_dir = \"../dataset/relevancy_ensemble/data_result/\"\n",
    "for file_name in tqdm(os.listdir(out_parent_dir)):\n",
    "    name_only = file_name.replace('.csv', '')\n",
    "    split, q_type, lang = name_only.split('_')\n",
    "    \n",
    "    dat = pd.read_csv(out_parent_dir + file_name)\n",
    "    data_stat.loc[lang,split][q_type] = len(dat)\n",
    "\n",
    "    if q_type == 'rephrase':\n",
    "        dat['concept'].tolist()\n",
    "        dat['name'].tolist()\n",
    "        dat['option'].tolist()\n",
    "        data_stat.loc[lang,split]['irr_concept'] = dat['concept'].tolist().count(True)\n",
    "        data_stat.loc[lang,split]['irr_location'] = dat['option'].tolist().count(True)\n",
    "        data_stat.loc[lang,split]['irr_names'] = dat['name'].tolist().count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>general</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>irr_concept</th>\n",
       "      <th>irr_location</th>\n",
       "      <th>irr_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">id</th>\n",
       "      <th>train</th>\n",
       "      <td>6040</td>\n",
       "      <td>2249</td>\n",
       "      <td>652</td>\n",
       "      <td>984</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>714</td>\n",
       "      <td>294</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>702</td>\n",
       "      <td>249</td>\n",
       "      <td>82</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">su</th>\n",
       "      <th>train</th>\n",
       "      <td>4697</td>\n",
       "      <td>2700</td>\n",
       "      <td>1245</td>\n",
       "      <td>984</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>546</td>\n",
       "      <td>353</td>\n",
       "      <td>171</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>564</td>\n",
       "      <td>294</td>\n",
       "      <td>132</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              general rephrase irr_concept irr_location irr_names\n",
       "id train         6040     2249         652          984      1035\n",
       "   validation     714      294          99          125       126\n",
       "   test           702      249          82          108       109\n",
       "su train         4697     2700        1245          984      1035\n",
       "   validation     546      353         171          125       126\n",
       "   test           564      294         132          108       109"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general         7456\n",
       "rephrase        2792\n",
       "irr_concept      833\n",
       "irr_location    1217\n",
       "irr_names       1270\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stat.loc['id'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general         5807\n",
       "rephrase        3347\n",
       "irr_concept     1548\n",
       "irr_location    1217\n",
       "irr_names       1270\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stat.loc['su'].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_parent_dir = \"../dataset/relevancy_ensemble/\"\n",
    "lang_name = \"su\"\n",
    "location_context = \"West Java\"\n",
    "\n",
    "loc_history_df = pd.read_csv(out_parent_dir + \"conceptnet-api-history.csv\")\n",
    "loc_response_history = dict((k, v) for k, v in zip(loc_history_df.prompt, loc_history_df.response) if ' ' not in k)\n",
    "\n",
    "activity_history_df = pd.read_csv(out_parent_dir + \"conceptnet-api-activity-history.csv\")\n",
    "activity_response_history = dict((k, v) for k, v in zip(activity_history_df.prompt, activity_history_df.response) if ' ' not in k)\n",
    "\n",
    "location_concepts = ['administrative_region', 'country', 'city', 'province']\n",
    "excluded = ['city', 'town', 'park', 'country', 'province', 'countryside', 'village']\n",
    "\n",
    "def is_conceptnet_location(option):\n",
    "    option = '_'.join(option.split())\n",
    "\n",
    "    if option in excluded:\n",
    "        return False\n",
    "\n",
    "    if option in loc_response_history:\n",
    "        return loc_response_history[option]\n",
    "    \n",
    "    res = requests.get(f\"https://api.conceptnet.io/query?node=/c/en/{option}&rel=/r/IsA\")\n",
    "    obj = res.json()\n",
    "    is_location = False\n",
    "    for edge in obj['edges']:\n",
    "        end_edge = edge['end']['@id'].split('/')\n",
    "        if any([e in end_edge for e in location_concepts]):\n",
    "            is_location = True\n",
    "            break\n",
    "    loc_response_history[option] = is_location\n",
    "    return is_location\n",
    "\n",
    "\n",
    "def is_conceptnet_activity(concept):\n",
    "    concept = '_'.join(concept.split())\n",
    "\n",
    "    if concept in activity_response_history:\n",
    "        return activity_response_history[concept]\n",
    "\n",
    "    res = requests.get(f\"https://api.conceptnet.io/query?node=/c/en/{concept}&rel=/r/IsA\")\n",
    "    obj = res.json()\n",
    "    \n",
    "    is_activity = False\n",
    "    if len(obj['edges']) == 0:\n",
    "        is_activity = True\n",
    "    else:\n",
    "        for edge in obj['edges']:\n",
    "            end_edge = edge['end']['@id'].split('/')\n",
    "            if 'activity' in end_edge:\n",
    "                is_activity = True\n",
    "                break\n",
    "\n",
    "    activity_response_history[concept] = is_activity\n",
    "    resp_history_df = pd.DataFrame({'prompt': activity_response_history.keys(), 'response': activity_response_history.values()})\n",
    "    resp_history_df.to_csv(out_parent_dir + \"conceptnet-api-activity-history.csv\", index=False)\n",
    "    \n",
    "    return is_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loc_response_history), len(activity_response_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = stanza.Pipeline('en', processors='tokenize,ner', device=0, model_dir=os.environ['HF_HOME'], download_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(sentence):\n",
    "    ner_results = ner_pipeline(sentence)\n",
    "    return [ent.text for ent in ner_results.ents if ent.type == 'PERSON']\n",
    "\n",
    "\n",
    "def extract_locations(sentence):\n",
    "    ner_results = ner_pipeline(sentence)\n",
    "    return [ent.text for ent in ner_results.ents if ent.type in ['GPE', 'LOC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.organization = os.environ['OPENAI_UILAB_KEY']\n",
    "resp_history_file = Path(out_parent_dir + \"gpt-3.5-history-\"+ lang_name +\"-230728.csv\")\n",
    "if resp_history_file.is_file():\n",
    "    print(\"Response history found!\")\n",
    "    resp_history_df = pd.read_csv(out_parent_dir + \"gpt-3.5-history-\"+ lang_name +\"-230728.csv\")\n",
    "    response_history = dict(zip(resp_history_df.prompt, resp_history_df.response))\n",
    "else:\n",
    "    print(\"Response history not found. Initializing new one...\")\n",
    "    response_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_prompts(concept, concept_type, location_name):\n",
    "    end_prompt = \"Answer with only 'yes' or 'no'.\"\n",
    "\n",
    "    if concept_type == \"activity\":\n",
    "        return [\n",
    "            f\"Can people {concept} in {location_name}? {end_prompt}\",\n",
    "            f\"Do people in {location_name} familiar with '{concept}' concept? {end_prompt}\",\n",
    "            f\"Can people in {location_name} {concept}? {end_prompt}\",\n",
    "            f\"Can {concept} be done in {location_name}? {end_prompt}\",\n",
    "            f\"Suppose you are a person who live in {location_name}. Can you {concept}? {end_prompt}\",\n",
    "        ]\n",
    "\n",
    "    return [\n",
    "        f\"Does {concept} commonly found in {location_name}? {end_prompt}\",\n",
    "        f\"Do people in {location_name} familiar with '{concept}' concept? {end_prompt}\",\n",
    "        f\"Can people find {concept} in {location_name}? {end_prompt}\",\n",
    "        f\"Is {concept} easily found in {location_name}? {end_prompt}\",\n",
    "        f\"Suppose you are a person who live in {location_name}. Can you find {concept}? {end_prompt}\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_openai_chat_completion(input_prompt, model_name, temp=0.2):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': input_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=temp\n",
    "    )\n",
    "\n",
    "\n",
    "def get_openai_relevancy(input_prompt, model_name):\n",
    "    if input_prompt in response_history:\n",
    "        return response_history[input_prompt]\n",
    "    \n",
    "    try:\n",
    "        completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "    except Exception:\n",
    "        time.sleep(60)\n",
    "        completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "\n",
    "    response = completion.choices[0].message.content.strip().lower()\n",
    "    \n",
    "    if response in [\"yes.\", \"no.\"]:\n",
    "        response = response.replace(\".\", \"\")\n",
    "    \n",
    "    response_history[input_prompt] = response\n",
    "    resp_history_df = pd.DataFrame({'prompt': response_history.keys(), 'response': response_history.values()})\n",
    "    resp_history_df.to_csv(out_parent_dir + \"gpt-3.5-history-\"+ lang_name +\"-230728.csv\", index=False)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_csqa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "relevancy_data = {\n",
    "    'q_id': [], 'question': [], 'q_concept': [],\n",
    "    'option_a': [], 'option_b': [], 'option_c': [], 'option_d': [], 'option_e': [],\n",
    "    'names': []\n",
    "}\n",
    "option_idxs = ['option_a', 'option_b', 'option_c', 'option_d', 'option_e']\n",
    "for item in tqdm(en_csqa):\n",
    "    relevancy_data['q_id'].append(item['id'])\n",
    "    relevancy_data['question'].append(item['question'])\n",
    "\n",
    "    prompt_type = \"activity\" if is_conceptnet_activity(item['question_concept']) else \"other\"\n",
    "    input_prompts = get_input_prompts(item['question_concept'], prompt_type, location_context)\n",
    "    rels = [get_openai_relevancy(input_prompt, model_name) for input_prompt in input_prompts]\n",
    "    relevancy_data['q_concept'].append(rels)\n",
    "\n",
    "    for option_idx, choice in zip(option_idxs, item['choices']['text']):\n",
    "        locations = extract_locations(choice)\n",
    "        if len(locations) > 0 or is_conceptnet_location(choice):\n",
    "            relevancy_data[option_idx].append(\"no\") # means irrelevant, has location\n",
    "        else:\n",
    "            relevancy_data[option_idx].append(\"yes\")\n",
    "        \n",
    "    names = extract_names(item['question'])\n",
    "    relevancy_data['names'].append(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancy_df = pd.DataFrame(relevancy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevancy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_parent_dir = \"../dataset/relevancy_ensemble/\"\n",
    "relevancy_df.to_csv(out_parent_dir + split_name + \"_\" + lang_name + \"_relevancy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
