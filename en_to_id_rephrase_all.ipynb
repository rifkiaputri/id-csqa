{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import time\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"API_KEY\")\n",
    "org_key = os.environ.get(\"ORG_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV Rephrase Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV file\n",
    "split = [\"validation\", \"test\", \"train\"]\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for s in split:\n",
    "    csv_file_path = f'{s}_rephrase.csv'\n",
    "\n",
    "    # Initialize an empty list to store the data\n",
    "    data_list = []\n",
    "\n",
    "    # Open the CSV file for reading\n",
    "    with open(csv_file_path, newline='') as csvfile:\n",
    "        # Create a CSV reader object\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        # Iterate through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            # Append the row (as a dictionary) to the data_list\n",
    "            row[\"choices\"] = ast.literal_eval(row[\"choices\"])\n",
    "\n",
    "            rephrase_params = [\"concept\", \"name\", \"option\"]\n",
    "            for param in rephrase_params:\n",
    "                if row[param] == \"True\":\n",
    "                    row[param] = True\n",
    "                elif row[param] == \"False\":\n",
    "                    row[param] = False\n",
    "                else:\n",
    "                    raise TypeError(f\"{param} data cannot be recognized\")\n",
    "\n",
    "            data_list.append(row)\n",
    "    \n",
    "    all_data[s] = data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate choice text\n",
    "def generate_choices_text(choices):\n",
    "    labels = choices[\"label\"]\n",
    "    texts = choices[\"text\"]\n",
    "\n",
    "    choice_text = \"\"\n",
    "    for idx, label in enumerate(labels):\n",
    "        choice_text += f'{label}. \"{texts[idx]}\"\\n'\n",
    "    \n",
    "    return choice_text\n",
    "\n",
    "# Function to generate answer text\n",
    "def generate_answer_text(choices, answerKey):\n",
    "    idx = choices[\"label\"].index(answerKey)\n",
    "    answer_text = f'{answerKey}. \"{choices[\"text\"][idx]}\"'\n",
    "    \n",
    "    return answer_text\n",
    "\n",
    "# Function to generate prompts based on the conditions\n",
    "def generate_rephrase_all_prompt(row):\n",
    "    return f\"\"\"Given a data consists of question, a concept, options, and question answer, change them to become related to Indonesia. If an element is marked to be changed, then you need to change it completely. If it's marked as keep, then keep as it is. Make sure your changes are still in the same domain/topic with the given data, and there is only one clear answer in the question answer for the question in the options. Reply with only your changed data in a JSON format.\n",
    "\n",
    "Data:\n",
    "###\n",
    "Question: {row['question']} -> Change\n",
    "Concept: {row['question_concept']} -> {'Change' if row['concept'] else 'Keep'}\n",
    "Options: -> {'Change' if row['option'] else 'Keep'}\n",
    "{generate_choices_text(row['choices'])}Question Answer: {generate_answer_text(row['choices'], row['answerKey']) if row['answerKey'] else ''}\n",
    "###\n",
    "\n",
    "Changed data:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rephrase Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_chat_completion(input_prompt, model_name):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': input_prompt \n",
    "            }\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        request_timeout=60,\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "# Define a function to rephrase the CSV data using OpenAI GPT-3.5-Turbo\n",
    "def rephrase_csv_data(row, model_name, history):\n",
    "    input_prompt = generate_rephrase_all_prompt(row)\n",
    "\n",
    "    if input_prompt in history.keys():\n",
    "        return input_prompt, history[input_prompt][\"response\"]\n",
    "\n",
    "    try:\n",
    "        completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "    except Exception:\n",
    "        print('Caught exception, wait for 1 min...')\n",
    "        time.sleep(60)\n",
    "        completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "    \n",
    "    response = completion.choices[0].message.content.strip()\n",
    "            \n",
    "    return input_prompt, response\n",
    "\n",
    "def postprocess_result(row, response):\n",
    "    rephrased_result = ast.literal_eval(response)\n",
    "    letters = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "    if isinstance(rephrased_result[\"Options\"], list):\n",
    "        if len(rephrased_result[\"Options\"]) == 5:\n",
    "            rephrased_result[\"Options\"] = dict(zip(letters, rephrased_result[\"Options\"]))\n",
    "        else:\n",
    "            option_labels = [option[0] for option in rephrased_result[\"Options\"]]\n",
    "            if set(option_labels).issubset(set(letters)):\n",
    "                option_texts = [option[4:] for option in rephrased_result[\"Options\"]]\n",
    "                label_not_in_option = list(set(letters) - set(option_labels))\n",
    "                for label in label_not_in_option:\n",
    "                    chosen_idx = row[\"choices\"][\"label\"].index(label)\n",
    "                    chosen_text = row[\"choices\"][\"text\"][chosen_idx]\n",
    "                    option_texts.insert(chosen_idx, chosen_text)\n",
    "\n",
    "                rephrased_result[\"Options\"] = dict(zip(letters, option_texts))\n",
    "            else:\n",
    "                raise ValueError(f\"Option output is not right: {rephrased_result['Options']}\")\n",
    "    \n",
    "    # if split != \"test\":\n",
    "    if rephrased_result[\"Question Answer\"][0] not in letters:\n",
    "        option_texts = [text.lower() for text in list(rephrased_result[\"Options\"].values())]\n",
    "        if rephrased_result['Question Answer'].lower() in option_texts:\n",
    "            option_labels = list(rephrased_result[\"Options\"].keys())\n",
    "            answer_idx = option_texts.index(rephrased_result['Question Answer'].lower())\n",
    "            rephrased_result[\"Question Answer\"] = option_labels[answer_idx]\n",
    "        else:\n",
    "            raise ValueError(f\"Answer key not in options: {rephrased_result['Question Answer']}\")\n",
    "    else:\n",
    "        rephrased_result[\"Question Answer\"] = rephrased_result[\"Question Answer\"][0]\n",
    "    \n",
    "    return rephrased_result\n",
    "\n",
    "def clean_data(row):\n",
    "    letters = {'a', 'b', 'c', 'd', 'e'}\n",
    "    alt_letters = {'b', 'c', 'd', 'e', 'f'}\n",
    "\n",
    "    options = row[\"choices\"][\"text\"]\n",
    "    labels = set([option[0].lower() for option in options])\n",
    "\n",
    "    if labels == letters or labels == alt_letters:\n",
    "        options = [option[4:] for option in options]\n",
    "    \n",
    "    options = [option.replace('\"', '') for option in options]\n",
    "    row[\"choices\"][\"text\"] = options\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Rephrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key\n",
    "openai.organization = org_key\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data on split: validation\n",
      "Load response history from file validation_history_91223.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/274 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [00:03<00:00, 75.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"validation_rephrased_91223.csv\" has been created with the data.\n",
      "Process data on split: test\n",
      "Load response history from file test_history_91223.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [00:02<00:00, 82.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"test_rephrased_91223.csv\" has been created with the data.\n",
      "Process data on split: train\n",
      "Load response history from file train_history_91223.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2162/2162 [01:30<00:00, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"train_rephrased_91223.csv\" has been created with the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for s in split:\n",
    "    print(f\"Process data on split: {s}\")\n",
    "    \n",
    "    history_path = f\"{s}_history_91223.csv\"\n",
    "    if os.path.exists(history_path):\n",
    "        print(f\"Load response history from file {history_path}\")\n",
    "        resp_history_df = pd.read_csv(history_path, converters={'response': lambda x: ast.literal_eval(x)})\n",
    "        response_history = dict(zip(resp_history_df.prompt, resp_history_df.response))\n",
    "    else:\n",
    "        print(f\"Initialize response history\")\n",
    "        response_history = {}\n",
    "\n",
    "    rephrased_results = []\n",
    "    for data in tqdm(all_data[s]):\n",
    "        rephrased_data = data.copy()\n",
    "\n",
    "        if data[\"concept\"] or data[\"option\"]:\n",
    "            prompt, response = rephrase_csv_data(data, model_name, response_history)\n",
    "            response_history[prompt] = {\"response\": response}\n",
    "            \n",
    "            resp_history_df = pd.DataFrame({'prompt': response_history.keys(), 'response': response_history.values()})\n",
    "            resp_history_df.to_csv(history_path, index=False)\n",
    "\n",
    "            result = postprocess_result(data, response)\n",
    "            # if isinstance(result, dict):\n",
    "            rephrased_data[\"question\"] = result[\"Question\"]\n",
    "            rephrased_data[\"choices\"] = {\n",
    "                \"label\": list(result[\"Options\"].keys()),\n",
    "                \"text\": [text.lower() for text in list(result[\"Options\"].values())],\n",
    "            }\n",
    "            if \"Concept\" in list(result.keys()):\n",
    "                rephrased_data[\"question_concept\"] = result[\"Concept\"]\n",
    "            # if s != \"test\":\n",
    "            rephrased_data[\"answerKey\"] = result[\"Question Answer\"]\n",
    "        # elif isinstance(result, str):\n",
    "        #     rephrased_data[\"question\"] = result\n",
    "        \n",
    "        rephrased_results.append(clean_data(rephrased_data))\n",
    "\n",
    "    # Specify the path to the CSV file\n",
    "    rephrased_file_path = f'{s}_rephrased_91223.csv'\n",
    "\n",
    "    # Get the keys from the first dictionary\n",
    "    header = rephrased_results[0].keys()\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    with open(rephrased_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the data\n",
    "        for row in rephrased_results:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f'CSV file \"{rephrased_file_path}\" has been created with the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
