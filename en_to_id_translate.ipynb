{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import time\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"API_KEY\")\n",
    "org_key = os.environ.get(\"ORG_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate prompts based on the conditions\n",
    "def generate_translate_prompt(row):\n",
    "    return f\"\"\"Translate all the text below to Indonesian:\n",
    "\n",
    "Question: {row['question']}\n",
    "Concept: {row['question_concept']}\n",
    "Options: {', '.join(row['choices']['text'])}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Request Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_chat_completion(input_prompt, model_name):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': input_prompt \n",
    "            }\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        request_timeout=60,\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "def get_openai_completion(input_prompt, model_name, max_tokens=256, temp=0.1, timeout=60):\n",
    "    completion = openai.Completion.create(\n",
    "        model=model_name,\n",
    "        prompt=input_prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temp,\n",
    "        request_timeout=timeout,\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "# Define a function to rephrase the CSV data using OpenAI GPT-3.5-Turbo\n",
    "def translate_csv_data(row, model_name, history, api_type=\"instruct\"):\n",
    "    input_prompt = generate_translate_prompt(row)\n",
    "\n",
    "    if input_prompt in history.keys():\n",
    "        return input_prompt, history[input_prompt][\"response\"]\n",
    "\n",
    "    if api_type == \"chat\":\n",
    "        try:\n",
    "            completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "        except Exception:\n",
    "            print('Caught exception, wait for 1 min...')\n",
    "            time.sleep(60)\n",
    "            completion = get_openai_chat_completion(input_prompt, model_name)\n",
    "        response = completion.choices[0].message.content.strip()\n",
    "\n",
    "    elif api_type == \"instruct\":\n",
    "        try:\n",
    "            completion = get_openai_completion(input_prompt, model_name)\n",
    "        except Exception:\n",
    "            print('Caught exception, wait for 1 min...')\n",
    "            time.sleep(60)\n",
    "            completion = get_openai_completion(input_prompt, model_name)\n",
    "        response = completion.choices[0].text.strip()\n",
    "            \n",
    "    return input_prompt, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Related Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(file_path):\n",
    "    data_list = []\n",
    "\n",
    "    with open(file_path, newline=\"\") as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            row[\"choices\"] = ast.literal_eval(row[\"choices\"])\n",
    "            data_list.append(row)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def save_data(samples, file_path):\n",
    "    header = samples[0].keys()\n",
    "\n",
    "    with open(file_path, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "        writer.writeheader()\n",
    "        for row in samples:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f'CSV file \"{file_path}\" has been created with the data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key\n",
    "openai.organization = org_key\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating file v3_test_name.csv\n",
      "Load response history from file ./eval/test/chatgpt-instruct/history_v3_test_name.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [01:02<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/test/chatgpt-instruct/translated_chatgpt_instruct_v3_test_name.csv\" has been created with the data.\n",
      "Translating file v3_test_both.csv\n",
      "Load response history from file ./eval/test/chatgpt-instruct/history_v3_test_both.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:09<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/test/chatgpt-instruct/translated_chatgpt_instruct_v3_test_both.csv\" has been created with the data.\n",
      "Translating file v3_test_concept.csv\n",
      "Load response history from file ./eval/test/chatgpt-instruct/history_v3_test_concept.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:19<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/test/chatgpt-instruct/translated_chatgpt_instruct_v3_test_concept.csv\" has been created with the data.\n",
      "Translating file v3_test_option.csv\n",
      "Load response history from file ./eval/test/chatgpt-instruct/history_v3_test_option.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/test/chatgpt-instruct/translated_chatgpt_instruct_v3_test_option.csv\" has been created with the data.\n",
      "Translating file v3_validation_name.csv\n",
      "Load response history from file ./eval/validation/chatgpt-instruct/history_v3_validation_name.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [01:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/validation/chatgpt-instruct/translated_chatgpt_instruct_v3_validation_name.csv\" has been created with the data.\n",
      "Translating file v3_validation_both.csv\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/validation/chatgpt-instruct/translated_chatgpt_instruct_v3_validation_both.csv\" has been created with the data.\n",
      "Translating file v3_validation_concept.csv\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:25<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/validation/chatgpt-instruct/translated_chatgpt_instruct_v3_validation_concept.csv\" has been created with the data.\n",
      "Translating file v3_validation_option.csv\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [01:00<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/validation/chatgpt-instruct/translated_chatgpt_instruct_v3_validation_option.csv\" has been created with the data.\n",
      "Translating file v3_train_name.csv\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [02:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/train/chatgpt-instruct/translated_chatgpt_instruct_v3_train_name.csv\" has been created with the data.\n",
      "Translating file v3_train_both.csv\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/train/chatgpt-instruct/translated_chatgpt_instruct_v3_train_both.csv\" has been created with the data.\n",
      "Translating file v3_train_concept.csv\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:32<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/train/chatgpt-instruct/translated_chatgpt_instruct_v3_train_concept.csv\" has been created with the data.\n",
      "Translating file v3_train_option.csv\n",
      "Initialize response history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:27<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"./eval/train/chatgpt-instruct/translated_chatgpt_instruct_v3_train_option.csv\" has been created with the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for folder in glob(\"./eval/*/\"):\n",
    "    for file in glob(f\"{folder}*.csv\"):\n",
    "        if \"v3\" in file:\n",
    "            fname = file.split(\"/\")[-1]\n",
    "            print(f\"Translating file {fname}\")\n",
    "\n",
    "            os.makedirs(f\"{folder}chatgpt-instruct/\", exist_ok=True)\n",
    "\n",
    "            history_path = f\"{folder}chatgpt-instruct/history_{fname}\"\n",
    "            if os.path.exists(history_path):\n",
    "                print(f\"Load response history from file {history_path}\")\n",
    "                resp_history_df = pd.read_csv(history_path, converters={'response': lambda x: ast.literal_eval(x)})\n",
    "                response_history = dict(zip(resp_history_df.prompt, resp_history_df.response))\n",
    "            else:\n",
    "                print(f\"Initialize response history\")\n",
    "                response_history = {}\n",
    "\n",
    "            file_data = load_csv_data(file)\n",
    "            for data in tqdm(file_data):\n",
    "                prompt, response = translate_csv_data(data, model_name, response_history)\n",
    "                response_history[prompt] = {\"response\": response}\n",
    "        \n",
    "                resp_history_df = pd.DataFrame({'prompt': response_history.keys(), 'response': response_history.values()})\n",
    "                resp_history_df.to_csv(history_path, index=False)\n",
    "\n",
    "                response = response.split(\"\\n\")\n",
    "                data[\"question\"] = str(response[0].split(\": \")[-1])\n",
    "                data[\"question_concept\"] = str(response[1].split(\": \")[-1]).lower()\n",
    "                data[\"choices\"][\"text\"] = response[2].split(\": \")[-1].lower().split(\", \")\n",
    "            \n",
    "            translated_file = f\"{folder}chatgpt-instruct/translated_chatgpt_instruct_{fname}\"\n",
    "            save_data(file_data, translated_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
